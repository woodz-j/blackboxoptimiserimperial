{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# Fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# Surrogate to maximise (negative for minimize)\n",
    "def surrogate_neg(x):\n",
    "    return -gp.predict(x.reshape(1, -1))[0]\n",
    "\n",
    "# Bounds for normalized inputs\n",
    "bounds = [(0,1), (0,1), (0,1), (0,1)]\n",
    "\n",
    "# Try multiple random starts to avoid local issues\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next point to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- New evaluated point ---\n",
    "x_new = np.array([0.973386, 0.889905, 0.981563, 0.242055])\n",
    "y_new = 2755.4496930419423\n",
    "\n",
    "# --- Add new data to dataset ---\n",
    "X_all = np.vstack([X_init, x_new])\n",
    "y_all = np.hstack([y_init, y_new])\n",
    "\n",
    "# --- Refit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Generate candidate next points around current best ---\n",
    "best_x = x_new\n",
    "sigma = 0.02  # tweak size for local exploration\n",
    "num_candidates = 5\n",
    "\n",
    "x_next_candidates = best_x + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "# Ensure all points are within [0,1]\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"Candidate next points to evaluate:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The new point still produced a very high yield, confirming that:\n",
    "You’re indeed near the global optimum.\n",
    "The response surface around the best point is smooth and relatively flat, so small parameter variations still yield high outputs.\n",
    "The optimum likely lies somewhere between those two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "✅ Adding both new high-yield points\n",
    "✅ Re-fitting the Gaussian Process with improved stability\n",
    "✅ Using a UCB-style acquisition for balanced exploration/exploitation\n",
    "✅ Local refinement with smaller perturbations (sigma = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- Add the two new data points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # best from previous run\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817]   # new high-yield point\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                # smaller noise term for precision\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5     # more robust kernel fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def surrogate_neg_ucb(x, kappa=2.0):\n",
    "    mean, std = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mean + kappa * std)\n",
    "\n",
    "# --- Search bounds for normalized inputs ---\n",
    "bounds = [(0, 1), (0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "# --- Optimize acquisition function for next sampling point ---\n",
    "best_x, best_val = None, float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "\n",
    "print(\"Suggested next point to evaluate:\", x_next)\n",
    "\n",
    "# --- Optionally: generate a few local perturbations for fine exploration ---\n",
    "sigma = 0.01\n",
    "num_candidates = 5\n",
    "x_next_candidates = x_next + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"\\nLocal candidate points for fine-tuning:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Suggested next point to evaluate:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New best: [0.999999, 0.999999, 0.999999, 0.024637]\n",
    "# 4440.50, which is a big jump over the previous best (~2755).\n",
    "# Implication 1: The optimum appears to lie at or extremely near the upper boundary for the first three variables (≈1.0).\n",
    "# Implication 2: The fourth variable is near zero (≈0.0246). Earlier high points had the fourth at ~0.24–0.30;\n",
    "# the new much better value suggests the peak may be at an extreme combination: first three maximized, fourth minimized.\n",
    "# Implication 3: Because the best is on (or very near) the boundary, we must be careful:\n",
    "# local symmetric perturbations may be misleading since you can’t go past 1.0.\n",
    "# The function may be unimodal but with its maximum on the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Because the optimum appears at extremes\n",
    "be cautious interpreting the GP far from observed data but your new top point strongly suggests a boundary optimum.\n",
    "The single most informative next experiment is the 1D sweep on the 4th variable while holding the first three at 1.0.\n",
    "That will tell you whether to push the fourth to exactly zero, or to some small positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # more robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "bounds = [(0,1),(0,1),(0,1),(0,1)]\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 1.0 ---\n",
    "fourth_grid = np.array([0.0, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 1.0) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([1.0, 1.0, 1.0, 0.0]),\n",
    "    np.array([0.995, 0.995, 0.995, 0.01]),\n",
    "    np.array([1.0, 1.0, 1.0, 0.05]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0, 1))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0, 1\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# --- TIGHTENED BOUNDS to avoid 0.0 or 1.0 ---\n",
    "bounds = [(0.02, 0.98)] * 4\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 0.98 (not 1.0 anymore) ---\n",
    "fourth_grid = np.array([0.02, 0.03, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 0.98) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([0.98, 0.98, 0.98, 0.02]),\n",
    "    np.array([0.97, 0.97, 0.97, 0.05]),\n",
    "    np.array([0.98, 0.98, 0.98, 0.1]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0.02, 0.98))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0.02, 0.98\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "- New point: [0.98, 0.98, 0.98, 0.02] → 3669.14.\n",
    "- Compare with prior highs:\n",
    "[0.9639, 0.8684, 0.9870, 0.2958] → 2574\n",
    "[0.9734, 0.8899, 0.9816, 0.2421] → 2755\n",
    "[0.999999,0.999999,0.999999,0.024637] → 4440.50 (best so far)\n",
    "- the model appears monotonic (or strongly increasing) in x1–x3 toward their upper edge, and prefers a small positive x4 near ~0.02–0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02] \n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume datain / dataout already loaded as before\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# fit GP (same settings)\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=8)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# bounds (tightened)\n",
    "bounds = [(0.02, 0.98)] * 4\n",
    "\n",
    "# 1D sweep for x4 with first three = 0.98\n",
    "fourth_grid = np.array([0.02, 0.025, 0.03, 0.04, 0.06])\n",
    "sweep_points = np.column_stack([np.full_like(fourth_grid, 0.98),\n",
    "                                np.full_like(fourth_grid, 0.98),\n",
    "                                np.full_like(fourth_grid, 0.98),\n",
    "                                fourth_grid])\n",
    "sweep_means = gp.predict(sweep_points)\n",
    "for p, m in zip(sweep_points, sweep_means):\n",
    "    print(p, \"→ predicted mean:\", m)\n",
    "\n",
    "# choose best sweep x4 (predicted) and create sensitivity tests for x1-3\n",
    "best_idx = np.argmax(sweep_means)\n",
    "best_x4 = fourth_grid[best_idx]\n",
    "\n",
    "first_three_tests = np.array([[v, v, v, best_x4] for v in [0.95, 0.97, 0.98]])\n",
    "print(\"\\nFirst-3 sensitivity candidates (x4 fixed):\")\n",
    "for p in first_three_tests:\n",
    "    print(p, \"→\", gp.predict(p.reshape(1,-1))[0])\n",
    "\n",
    "# local perturbations around [0.98,0.98,0.98,best_x4]\n",
    "sigma = 0.005\n",
    "local_cands = np.clip(np.tile([0.98,0.98,0.98,best_x4], (6,1)) + np.random.normal(0, sigma, (6,4)), 0.02, 0.98)\n",
    "print(\"\\nLocal perturbation candidates:\")\n",
    "for p in local_cands:\n",
    "    print(p, \"→\", gp.predict(p.reshape(1,-1))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assumes gp is already fitted and new_points etc. are in place ---\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1) Reuse the previously computed best_x if you have it; otherwise run acquisition optimization quickly:\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# quick acquisition optimization to get a candidate (optional)\n",
    "bounds = [(0.02,0.98)]*4\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "seeds = [new_points[-1], np.array([0.98,0.98,0.98,0.02]), np.array([0.97,0.97,0.97,0.05])]\n",
    "for _ in range(6):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0.02, 0.98))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B', options={'maxiter':100})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2) Build candidate list: sweep on x4 (x1-3 = 0.98), the acquisition best_x, and a few local perturbs\n",
    "fourth_grid = np.array([0.02, 0.025, 0.03, 0.04, 0.06])\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    fourth_grid\n",
    "])\n",
    "\n",
    "# local perturbations around best_x\n",
    "np.random.seed(0)\n",
    "local = np.clip(best_x + np.random.normal(0, 0.005, size=(5,4)), 0.02, 0.98)\n",
    "\n",
    "# combine and deduplicate\n",
    "candidates = np.vstack([sweep_points, local, best_x.reshape(1,-1)])\n",
    "# optional: remove duplicates (numerically)\n",
    "unique_candidates = np.unique(np.round(candidates, 6), axis=0)\n",
    "\n",
    "# 3) Evaluate GP predictive mean and pick single best\n",
    "means = gp.predict(unique_candidates)\n",
    "best_idx = np.argmax(means)\n",
    "single_best = unique_candidates[best_idx]\n",
    "\n",
    "print(\"Single best candidate (highest predicted mean):\", single_best)\n",
    "print(\"Predicted mean yield:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(single_best, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "- [0.980000, 0.980000, 0.980000, 0.060000] Essentially identical to previous point (~0.0001 higher)\n",
    "- [0.999999,0.999999,0.999999,0.024637] 4440 Peak observed so far, very high first three inputs, small x4 (~0.0246)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "- By keeping bounds artificially tight I may be preventing access to higher yields.\n",
    "- Relaxing the bounds toward 1.0 will very likely increase yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- LOAD EXISTING DATA (your above snippet) ---\n",
    "\n",
    "# --- Fit GP (same settings you've been using) ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=8)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Build candidate set that probes toward the boundary safely ---\n",
    "# grid for x1-x3 near boundary (you can change values)\n",
    "x_levels = np.array([0.98, 0.985, 0.99, 0.995])  # include 1.0 only if allowed\n",
    "# keep x4 near the small region we've seen best\n",
    "x4_levels = np.array([0.02, 0.025, 0.03, 0.04])\n",
    "\n",
    "candidates = []\n",
    "for a in x_levels:\n",
    "    for b in x4_levels:\n",
    "        candidates.append([a, a, a, b])\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Optionally, remove candidates equal to points you've already tested (to avoid duplication)\n",
    "# (simple numeric comparison, adjust tolerance if necessary)\n",
    "def not_duplicate(c, X_existing, tol=1e-6):\n",
    "    return not np.any(np.all(np.abs(X_existing - c) <= tol, axis=1))\n",
    "\n",
    "filtered = np.array([c for c in candidates if not_duplicate(c, X_all)])\n",
    "if filtered.shape[0] == 0:\n",
    "    filtered = candidates  # fallback if everything was present\n",
    "\n",
    "# --- Predictive means and uncertainties ---\n",
    "means, stds = gp.predict(filtered, return_std=True)\n",
    "\n",
    "# --- Rank by predicted mean (descending) ---\n",
    "order = np.argsort(means)[::-1]\n",
    "ranked = filtered[order]\n",
    "ranked_means = means[order]\n",
    "ranked_stds = stds[order]\n",
    "\n",
    "# Print top-k candidates\n",
    "k = min(6, len(ranked))\n",
    "print(\"Top candidates to probe toward boundary (ranked by GP mean):\")\n",
    "for i in range(k):\n",
    "    print(f\"{i+1}: {ranked[i]}  predicted_mean={ranked_means[i]:.2f}, std={ranked_stds[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "- New point: [0.995, 0.995, 0.995, 0.03] → 4236.36.\n",
    "- This sits between the 0.98-triple results (~3669) and the unconstrained 1.0-triple best (4440.50).\n",
    "- Consistent pattern: increasing x1–x3 toward 1.0 yields large, roughly monotonic gains. x4 around 0.02–0.03 remains in the sweet-spot (and shows a fairly flat plateau).\n",
    "- Takeaway: you’re seeing strong, consistent improvement as you step from 0.98 → 0.995 → 1.0 for x1–x3. The unconstrained corner still looks best, but 0.995 captured most of the gain already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- assume datain, dataout already loaded ---\n",
    "# append latest result above\n",
    "\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=6)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# build candidate set probing to boundary (adjust including 1.0 only if allowed)\n",
    "x_levels = np.array([0.995, 0.997, 0.999])  # remove 1.0 if disallowed\n",
    "x4_levels = np.array([0.02, 0.025, 0.03])\n",
    "\n",
    "candidates = np.array([[a, a, a, b] for a in x_levels for b in x4_levels])\n",
    "\n",
    "# remove duplicates already tested\n",
    "def not_duplicate(c, X_exist, tol=1e-8):\n",
    "    return not np.any(np.all(np.abs(X_exist - c) <= tol, axis=1))\n",
    "\n",
    "cand_filtered = np.array([c for c in candidates if not_duplicate(c, X_all)])\n",
    "if cand_filtered.size == 0:\n",
    "    cand_filtered = candidates  # fallback\n",
    "\n",
    "# predict means and pick highest-mean candidate\n",
    "means = gp.predict(cand_filtered)\n",
    "best_idx = np.argmax(means)\n",
    "single_best = cand_filtered[best_idx]\n",
    "print(\"Single best exploitation pick:\", single_best, \"predicted mean:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "- [0.999, 0.999, 0.999, 0.02] → 4399.07 is very close to the best observed 4440.50 at the near-exact corner.\n",
    "- The data show a consistent, roughly monotonic rise in yield as x1–x3 move from 0.98 → 0.995 → 0.999 → 1.0, with x4 small (~0.02–0.03) giving the best results.\n",
    "- Diminishing returns are apparent: the step from 0.995 → 0.999 produced a substantial gain, but the last step to 1.0 yields a relatively small expected improvement (~41 units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# fit GP\n",
    "gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-8, normalize_y=True, n_restarts_optimizer=6)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# candidate set (include exact corner only if allowed)\n",
    "candidates = np.array([\n",
    "    [0.9995, 0.9995, 0.9995, 0.025],\n",
    "    [0.999, 0.999, 0.999, 0.025],\n",
    "    [0.995, 0.995, 0.995, 0.025],\n",
    "    [0.98, 0.98, 0.98, 0.03]\n",
    "])\n",
    "# filter duplicates\n",
    "candidates = np.array([c for c in candidates if not np.any(np.all(np.isclose(X_all, c, atol=1e-8), axis=1))])\n",
    "\n",
    "means = gp.predict(candidates)\n",
    "best_idx = np.argmax(means)\n",
    "print(\"Single best candidate:\", candidates[best_idx], \"predicted mean:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ===============================\n",
    "# Gaussian Process Model\n",
    "# ===============================\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# ===============================\n",
    "# Acquisition Function (UCB)\n",
    "# ===============================\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# ===============================\n",
    "# Bounds (avoid hitting exact 0 or 1)\n",
    "# ===============================\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1 - eps)] * 4\n",
    "\n",
    "# ===============================\n",
    "# 1D Sweep — keep first 3 ≈ high region\n",
    "# ===============================\n",
    "fourth_grid = np.array([0.002, 0.005, 0.01, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2])\n",
    "\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    fourth_grid\n",
    "])\n",
    "\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep predictions for varying 4th variable:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# ===============================\n",
    "# Acquisition Optimization\n",
    "# ===============================\n",
    "best_x, best_val = None, float('inf')\n",
    "\n",
    "seeds = [\n",
    "    new_points[-1].clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, eps]),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.02]).clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.05]).clip(eps, 1-eps),\n",
    "]\n",
    "\n",
    "# jittered seeds near current high-yield region\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, eps, 1 - eps))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds,\n",
    "                   method='L-BFGS-B', options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "print(\"Next point (6 dp):\", np.round(best_x, 6))\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Local candidate set around best_x\n",
    "# ===============================\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# Combine with sweep top points and best_x\n",
    "candidates = np.vstack([\n",
    "    top_sweep_points,\n",
    "    local_candidates,\n",
    "    best_x.reshape(1, -1)\n",
    "])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "- [0.999, 0.999, 0.999, 0.03] → 4399.08 is almost identical to your previous near-corner results.\n",
    "- This confirms: (a) x1–x3 near 0.999 produce very high yield, and (b) x4 in the small range ≈0.02–0.03 lies on a flat plateau (changing x4 a little doesn’t matter much)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.030000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082, \n",
    "    4399.0827883838065\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ===============================\n",
    "# Gaussian Process Model\n",
    "# ===============================\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "cand1 = np.array([1.0,1.0,1.0,0.025]).reshape(1,-1)         # if allowed\n",
    "cand2 = np.array([0.9995,0.9995,0.9995,0.025]).reshape(1,-1)\n",
    "cand3 = np.array([0.999,0.999,0.999,0.025]).reshape(1,-1)\n",
    "print(\"GP mean cand1:\", gp.predict(cand1)[0])\n",
    "print(\"GP mean cand2:\", gp.predict(cand2)[0])\n",
    "print(\"GP mean cand3:\", gp.predict(cand3)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Acquisition Function (UCB)\n",
    "# ===============================\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# ===============================\n",
    "# Bounds (avoid hitting exact 0 or 1)\n",
    "# ===============================\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1 - eps)] * 4\n",
    "\n",
    "# ===============================\n",
    "# 1D Sweep — keep first 3 ≈ high region\n",
    "# ===============================\n",
    "fourth_grid = np.array([0.002, 0.005, 0.01, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2])\n",
    "\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    fourth_grid\n",
    "])\n",
    "\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep predictions for varying 4th variable:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# ===============================\n",
    "# Acquisition Optimization\n",
    "# ===============================\n",
    "best_x, best_val = None, float('inf')\n",
    "\n",
    "seeds = [\n",
    "    new_points[-1].clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, eps]),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.02]).clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.05]).clip(eps, 1-eps),\n",
    "]\n",
    "\n",
    "# jittered seeds near current high-yield region\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, eps, 1 - eps))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds,\n",
    "                   method='L-BFGS-B', options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "print(\"Next point (6 dp):\", np.round(best_x, 6))\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Local candidate set around best_x\n",
    "# ===============================\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# Combine with sweep top points and best_x\n",
    "candidates = np.vstack([\n",
    "    top_sweep_points,\n",
    "    local_candidates,\n",
    "    best_x.reshape(1, -1)\n",
    "])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "- [0.999000, 0.999000, 0.999000, 0.644120] - 5046.56629041423 is a new peak\n",
    "- The first three coordinates (x1–x3) remain near the high-yield corner, which is consistent with earlier trends.\n",
    "- The 4th coordinate, x4 = 0.644, is much higher than previous “small x4” plateau (~0.02–0.03).\n",
    "- Yet the yield jumped to 5046, which is higher than any previous measurement, including the unconstrained corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.644120]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082, \n",
    "    4399.0827883838065,\n",
    "    5046.56629041423\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "- This code generates a set of top candidate points around this new peak for further evaluation, while avoiding exact 1.0 and 0.0\n",
    "- I am constraining the query strategy to focus on this point\n",
    "- All high yields so far are clustered in one region\n",
    "- Earlier broad exploration did not reveal competing peaks\n",
    "- The jump from 4,400 → 5,046 came from relaxing x4, not moving away in x1–x3\n",
    "- Note: If the true global maximum lies far away (e.g. x1 ≈ 0.92, x4 ≈ 0.8), the current strategy would miss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Fit GP ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-8,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=8)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Interior bounds to avoid exact 0/1 ---\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1-eps)] * 4\n",
    "\n",
    "# --- Generate candidate points near the new peak ---\n",
    "# Small perturbations around x1–x3 ≈ 0.999, x4 ≈ 0.644\n",
    "num_candidates = 10\n",
    "sigma = 0.005  # local jitter\n",
    "\n",
    "base_point = np.array([0.999, 0.999, 0.999, 0.644120])\n",
    "local_candidates = np.clip(\n",
    "    base_point + np.random.normal(0, sigma, size=(num_candidates, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# --- Optionally include a few points with slightly lower x1–x3 to explore local slope ---\n",
    "explore_candidates = []\n",
    "x_levels = [0.995, 0.997, 0.999]\n",
    "x4_levels = [0.62, 0.63, 0.64, 0.65, 0.66]\n",
    "for a in x_levels:\n",
    "    for b in x4_levels:\n",
    "        explore_candidates.append([a, a, a, b])\n",
    "\n",
    "explore_candidates = np.array(explore_candidates)\n",
    "\n",
    "# --- Combine and remove duplicates ---\n",
    "def not_duplicate(c, X_exist, tol=1e-8):\n",
    "    return not np.any(np.all(np.abs(X_exist - c) <= tol, axis=1))\n",
    "\n",
    "all_candidates = np.vstack([local_candidates, explore_candidates])\n",
    "filtered_candidates = np.array([c for c in all_candidates if not_duplicate(c, X_all)])\n",
    "\n",
    "# --- Predict GP mean for each candidate ---\n",
    "means = gp.predict(filtered_candidates)\n",
    "best_idx = np.argmax(means)\n",
    "\n",
    "print(\"Top candidate to evaluate next:\", filtered_candidates[best_idx])\n",
    "print(\"Predicted mean yield:\", means[best_idx])\n",
    "\n",
    "# --- Optional: print top 5 candidates ---\n",
    "top5_idx = np.argsort(means)[-5:][::-1]\n",
    "print(\"\\nTop 5 candidates:\")\n",
    "for i in top5_idx:\n",
    "    print(filtered_candidates[i], \"→ predicted mean:\", means[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(filtered_candidates[best_idx], 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Week 11\n",
    "- keeping x₁, x₂, x₃ ≈ 1.0 produces the highest yields observed.\n",
    "- This new point at x₄ ≈ 0.6565 improves further to ≈5099\n",
    "- The improvement is incremental, not erratic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.644120],\n",
    "    [0.999000, 0.999000, 0.999000, 0.656538]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082, \n",
    "    4399.0827883838065,\n",
    "    5046.56629041423,\n",
    "    5098.503707082563\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "- Early rounds sampled broadly across the 4D space, including low, mid, and high values of all variables.\n",
    "- None of those regions produced yields even remotely close to what you’re now seeing (≈5,000).\n",
    "- As sampling density increased near the corner, the yield improved smoothly and consistently, which is characteristic of a single dominant peak rather than multiple competing maxima.\n",
    "- The GP has repeatedly validated its predictions with real evaluations, reducing the risk of model-driven bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "- Lower exploration\n",
    "- Narrow the local search\n",
    "- Add a small deterministic sweep in x₄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -----------------------------\n",
    "# Fit GP (unchanged structure)\n",
    "# -----------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)   # X_all, y_all include the new point\n",
    "\n",
    "# -----------------------------\n",
    "# Interior bounds (unchanged)\n",
    "# -----------------------------\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1 - eps)] * 4\n",
    "\n",
    "# -----------------------------\n",
    "# Acquisition: lower exploration\n",
    "# -----------------------------\n",
    "def acq_neg_ucb(x, kappa=0.5):   # reduced from ~2.0\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# -----------------------------\n",
    "# Start from current best\n",
    "# -----------------------------\n",
    "current_best = np.array([0.999, 0.999, 0.999, 0.656538])\n",
    "\n",
    "res = minimize(\n",
    "    acq_neg_ucb,\n",
    "    x0=current_best,\n",
    "    bounds=bounds,\n",
    "    method=\"L-BFGS-B\",\n",
    "    options={\"maxiter\": 200}\n",
    ")\n",
    "\n",
    "best_x = res.x\n",
    "print(\"Acquisition-opt suggested next point:\", best_x)\n",
    "\n",
    "# -----------------------------\n",
    "# Local refinement (anisotropic)\n",
    "# -----------------------------\n",
    "# Very small movement in x1–x3, more freedom in x4\n",
    "sigma = np.array([0.002, 0.002, 0.002, 0.01])\n",
    "num_local = 6\n",
    "\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_local, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Deterministic x4 bracketing\n",
    "# -----------------------------\n",
    "x4_grid = np.linspace(0.64, 0.68, 7)\n",
    "bracket_points = np.column_stack([\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    x4_grid\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Combine candidates\n",
    "# -----------------------------\n",
    "candidates = np.vstack([\n",
    "    best_x.reshape(1, -1),\n",
    "    local_candidates,\n",
    "    bracket_points\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Rank by predicted mean\n",
    "# -----------------------------\n",
    "means = gp.predict(candidates)\n",
    "order = np.argsort(means)[::-1]\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i in order:\n",
    "    print(candidates[i], \"→ predicted mean:\", means[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "# Acquisition-opt\n",
    "- This is the single point found by optimizing the acquisition function (here, UCB) using a continuous optimizer (L-BFGS-B).\n",
    "- this is the mathematically best choice according to the GP + acquisition.\n",
    "# Candidate next points (A set of practical evaluation options)\n",
    "- The acquisition-optimal point\n",
    "- Random local perturbations around it\n",
    "- Deterministic bracketing points (e.g. x₄ sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(best_x, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "# Week 12\n",
    "- Reinforces the dominance of x₁–x₃ near 1.0. Once again, keeping the first three inputs at ≈0.999 yields the best performance. There is still no evidence that reducing any of these improves yield, so their role as strong, monotonic drivers is confirmed.\n",
    "- Earlier results suggested a local peak around x₄ ≈0.64–0.66 (~5,100). This new point at x₄ ≈0.81 jumps significantly higher to ~6,100, indicating that the response in x₄ is not a single narrow peak at 0.65 but continues rising (or has another interior maximum) as x₄ increases.\n",
    "- The optimization has not been misled; instead, it is progressively uncovering structure that wasn’t visible earlier due to interaction effects.\n",
    "The search should now continue probing x₄ upward, but with controlled steps, to determine whether:\n",
    "- The yield continues increasing toward the upper bound, or\n",
    "- It eventually plateaus or turns over before x₄ = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "print(datain)\n",
    "print(dataout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.644120],\n",
    "    [0.999000, 0.999000, 0.999000, 0.656538],\n",
    "    [0.999000, 0.999000, 0.999000, 0.814445]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082, \n",
    "    4399.0827883838065,\n",
    "    5046.56629041423,\n",
    "    5098.503707082563,\n",
    "    6103.776797272247\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -----------------------------\n",
    "# Fit GP (unchanged structure)\n",
    "# -----------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)   # X_all, y_all include the new point\n",
    "\n",
    "# -----------------------------\n",
    "# Interior bounds (unchanged)\n",
    "# -----------------------------\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1 - eps)] * 4\n",
    "\n",
    "# -----------------------------\n",
    "# Acquisition: lower exploration\n",
    "# -----------------------------\n",
    "def acq_neg_ucb(x, kappa=0.3):   # reduced from ~2.0\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# -----------------------------\n",
    "# Start from current best\n",
    "# -----------------------------\n",
    "current_best = np.array([0.999, 0.999, 0.999, 0.814445])\n",
    "\n",
    "res = minimize(\n",
    "    acq_neg_ucb,\n",
    "    x0=current_best,\n",
    "    bounds=bounds,\n",
    "    method=\"L-BFGS-B\",\n",
    "    options={\"maxiter\": 200}\n",
    ")\n",
    "\n",
    "best_x = res.x\n",
    "print(\"Acquisition-opt suggested next point:\", best_x)\n",
    "\n",
    "# -----------------------------\n",
    "# Local refinement (anisotropic)\n",
    "# -----------------------------\n",
    "# x₁–x₃ are essentially saturated\n",
    "# x₄ is still actively improving and deserves more freedom\n",
    "sigma = np.array([0.001, 0.001, 0.001, 0.015])\n",
    "\n",
    "num_local = 6\n",
    "\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_local, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Deterministic x4 bracketing\n",
    "# -----------------------------\n",
    "# x4_grid = np.linspace(0.64, 0.68, 7)\n",
    "# move the x₄ bracketing range upward because every reliable measurement so far shows that higher yields occur at larger x₄ values,\n",
    "# making lower ranges no longer informative.\n",
    "# Center around the current best - Your best is ≈ 0.814\n",
    "# Lower side (≈0.78) checks whether the peak is behind us\n",
    "# Upper side (≈0.88) checks whether the function is still rising\n",
    "# 7 is the number of points you want to generate in that interval.\n",
    "x4_grid = np.linspace(0.78, 0.88, 7)\n",
    "bracket_points = np.column_stack([\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    np.full_like(x4_grid, 0.999),\n",
    "    x4_grid\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Combine candidates\n",
    "# -----------------------------\n",
    "candidates = np.vstack([\n",
    "    best_x.reshape(1, -1),\n",
    "    local_candidates,\n",
    "    bracket_points\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Rank by predicted mean\n",
    "# -----------------------------\n",
    "means = gp.predict(candidates)\n",
    "order = np.argsort(means)[::-1]\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i in order:\n",
    "    print(candidates[i], \"→ predicted mean:\", means[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(best_x, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
