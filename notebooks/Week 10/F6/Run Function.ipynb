{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it‚Äôs an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it‚Äôs an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "#X_init = ... # 20x5 array\n",
    "#y_init = ... # 20 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Define Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0,1)]*5  # 5 ingredients\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# Multiple random starts to avoid local maxima\n",
    "for _ in range(20):\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Step 0: Load and update data ---\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# Add the most recent data point\n",
    "x_new = np.array([[0.861642, 0.308166, 0.510818, 0.325615, 0.845503]])\n",
    "y_new = np.array([-1.7791349472320002])\n",
    "\n",
    "# Combine with existing data\n",
    "X_init = np.vstack([datain, x_new])\n",
    "y_init = np.hstack([dataout, y_new])\n",
    "\n",
    "print(X_init)\n",
    "print(y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init   # since we want to make score close to zero (maximise negative of total)\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)\n",
    "\n",
    "# --- Step 3: Define acquisition functions ---\n",
    "\n",
    "# Expected Improvement (EI)\n",
    "def expected_improvement(x, gp, y_best, xi=0.05):  # adjust xi for exploration/exploitation balance\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # we minimize in scipy\n",
    "\n",
    "# --- (Optional) UCB version: uncomment to use ---\n",
    "# def ucb(x, gp, kappa=2.0):\n",
    "#     x = np.array(x).reshape(1, -1)\n",
    "#     mu, sigma = gp.predict(x, return_std=True)\n",
    "#     return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0, 1)] * 5\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "\n",
    "for _ in range(40):  # more restarts to reduce local optima risk\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    # --- For UCB, replace expected_improvement(...) with ucb(...)\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Summary of changes:\n",
    "‚úÖ Added the two new data points (x_new1, x_new2)\n",
    "‚úÖ Reduced xi from 0.02 to 0.01 ‚Üí focuses on exploitation\n",
    "‚úÖ Increased random restarts to 50 for robustness\n",
    "üí¨ Kept UCB commented out (can easily be enabled later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Step 0: Load and update data ---\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# Add previously tested new points\n",
    "x_new1 = np.array([[0.861642, 0.308166, 0.510818, 0.325615, 0.845503]])\n",
    "y_new1 = np.array([-1.7791349472320002])\n",
    "\n",
    "x_new2 = np.array([[0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269]])\n",
    "y_new2 = np.array([-1.3401340011620242])\n",
    "\n",
    "# Combine with existing data\n",
    "X_init = np.vstack([datain, x_new1, x_new2])\n",
    "y_init = np.hstack([dataout, y_new1, y_new2])\n",
    "\n",
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)\n",
    "\n",
    "# --- Step 3: Define acquisition functions ---\n",
    "\n",
    "# Expected Improvement (EI)\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):  # reduced xi for more exploitation\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize because scipy.optimize minimizes by default\n",
    "\n",
    "# --- (Optional) UCB version: uncomment to use ---\n",
    "# def ucb(x, gp, kappa=2.0):\n",
    "#     x = np.array(x).reshape(1, -1)\n",
    "#     mu, sigma = gp.predict(x, return_std=True)\n",
    "#     return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0, 1)] * 5\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "\n",
    "for _ in range(50):  # increased restarts for better global search\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    # --- For UCB, replace expected_improvement(...) with ucb(...)\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Next recipe to try:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The new point [0.304171, 0.964306, 0.527203, 0.006037, 0.376271] gave -1.8371,\n",
    "which is worse than the previous new samples and far worse than the current best (-0.7143).\n",
    "That tells us this region of input space is likely a poor area ‚Äî we should record it and let the GP learn low values there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Add the new point to the dataset and refit the GP.\n",
    "Use Expected Improvement (EI) as the acquisition function but reduce xi to favor exploitation (I recommend xi = 0.005‚Äì0.01).\n",
    "Compute one exploratory candidate using UCB with a larger kappa like 3.0) so you can occasionally sample high-uncertainty regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271])   # most recent\n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3])\n",
    "\n",
    "# transform for maximization\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# Fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# Acquisition: Expected Improvement\n",
    "def expected_improvement(x, gp, y_best, xi=0.005):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize\n",
    "\n",
    "# Optional: Upper Confidence Bound (for exploration)\n",
    "def ucb(x, gp, kappa=3.0):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "bounds = [(0.0, 1.0)] * X.shape[1]\n",
    "\n",
    "# Helper optimizer that runs many restarts and also starts near a given seed\n",
    "def optimize_acq(acq_func, gp, y_best, n_restarts=40, local_seeds=None):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "    # global random restarts\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(X.shape[1])\n",
    "        res = minimize(lambda xx: acq_func(xx, gp, y_best),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    # local starts near seeds (if provided)\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(8):  # a few noisy local starts\n",
    "                x0 = seed + 0.05 * np.random.randn(X.shape[1])\n",
    "                x0 = np.clip(x0, 0.0, 1.0)\n",
    "                res = minimize(lambda xx: acq_func(xx, gp, y_best),\n",
    "                               x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "    return best_x, best_val\n",
    "\n",
    "# Identify current best input (from the dataset)\n",
    "idx_best = np.argmax(y_trans)  # index of best transformed value\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# Exploitative candidate: EI with local seeds near current best\n",
    "x_next_exploit, val_e = optimize_acq(expected_improvement, gp, y_best,\n",
    "                                     n_restarts=40, local_seeds=[x_best])\n",
    "\n",
    "# Exploratory candidate: high-kappa UCB (optional)\n",
    "x_next_explore, val_u = optimize_acq(lambda xx,gp,yb: ucb(xx,gp,kappa=3.0), gp, y_best,\n",
    "                                     n_restarts=40, local_seeds=None)\n",
    "\n",
    "print(\"Current best (transformed):\", y_best, \"at X =\", x_best)\n",
    "print(\"Exploitative next (EI, xi=0.005):\", x_next_exploit)\n",
    "print(\"Exploratory next (UCB, kappa=3.0):\", x_next_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Going with Exploitative next (EI, xi=0.005): [0.13368735 0.61046861 0.48527119 0.33635839 0.75270271]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_exploit, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "- New input: [0.133687, 0.610469, 0.485271, 0.336358, 0.752703] ‚Üí output -1.7633.\n",
    "- That neighborhood already contains several poor values, so the new -1.76 is consistent with (and reinforces) that assessment.\n",
    "- EI will be pushed toward regions with higher predicted means (the good basins) once the GP is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "- The new sample confirmed that part of the space is bad ‚Äî don‚Äôt waste more samples there now.\n",
    "- Focus on small, local steps around the current best to climb the nearby basin,\n",
    "- but keep one periodic, deliberate exploration to escape local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   # most recent\n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Computes one next point using Expected Improvement (EI) (exploit),\n",
    "Computes one next point using Upper Confidence Bound (UCB) (explore).\n",
    "- We are going to use the exploit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y        # since we want to bring score toward 0\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Acquisition Functions ===\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0:\n",
    "        return 0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization in scipy\n",
    "\n",
    "def ucb(x, kappa=2.5):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative for minimization\n",
    "\n",
    "# === Optimize acquisition function ===\n",
    "bounds = [(0,1)] * 5\n",
    "\n",
    "def optimize(acq):\n",
    "    best_x = None\n",
    "    best_val = float(\"inf\")\n",
    "    for _ in range(40):  # multiple random restarts\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(acq, x0=x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# === Next point to evaluate ===\n",
    "x_next_EI = optimize(expected_improvement)\n",
    "# x_next_UCB = optimize(lambda x: ucb(x))   # ‚Üê Uncomment to use exploration candidate\n",
    "\n",
    "print(\"Next exploitative EI point:\", x_next_EI)\n",
    "# print(\"Next exploratory UCB point:\", x_next_UCB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_EI, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "#\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "- this new sample (-1.5449) is better than several recent poor probes but still not close to the best (-0.7143).\n",
    "- It strengthens the GP‚Äôs belief that its neighbourhood is mediocre, so the next step is to refit the GP with this point and then pick an exploitative candidate (EI with a small xi) plus an optional exploratory probe (UCB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# transform (we maximize -y)\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# acquisition functions\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization\n",
    "\n",
    "def ucb(x, kappa=3.0):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "bounds = [(0,1)]*5\n",
    "\n",
    "# optimizer with both random restarts and optional local seeds near x_best\n",
    "def optimize_acq(acq, local_seeds=None, n_restarts=40):\n",
    "    best_x = None\n",
    "    best_val = float('inf')\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(lambda xx: acq(xx), x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(8):\n",
    "                x0 = seed + 0.03 * np.random.randn(5)\n",
    "                x0 = np.clip(x0, 0, 1)\n",
    "                res = minimize(lambda xx: acq(xx), x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# identify current best input from data\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# get candidates\n",
    "x_next_exploit = optimize_acq(expected_improvement, local_seeds=[x_best], n_restarts=50)\n",
    "x_next_explore = optimize_acq(lambda xx: ucb(xx, kappa=3.0), local_seeds=None, n_restarts=40)\n",
    "\n",
    "print(\"EI exploit candidate:\", x_next_exploit)\n",
    "print(\"UCB explore candidate:\", x_next_explore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_exploit, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(\"------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "\n",
    "x_new6 = np.array([0.362488, 0.030495, 0.284038, 0.329972, 0.326837])   # most recent\n",
    "y_new6 = -1.4257489720250607\n",
    "#\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5, x_new6])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5, y_new6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "- The neighborhood around [0.362, 0.030, 0.284, 0.330, 0.327] is moderately bad.\n",
    "- Updating the GP with this point will:\n",
    "- Lower the predicted mean in this region.\n",
    "- Reduce uncertainty locally.\n",
    "- This means EI will naturally avoid this area in future iterations, focusing more on regions near the current best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Load existing dataset ===\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Acquisition functions ===\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization in scipy\n",
    "\n",
    "def ucb(x, kappa=3.0):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative for minimization\n",
    "\n",
    "bounds = [(0,1)]*5\n",
    "\n",
    "# === Optimizer with global restarts and optional local seeds near x_best ===\n",
    "def optimize_acq(acq, local_seeds=None, n_restarts=40):\n",
    "    best_x = None\n",
    "    best_val = float('inf')\n",
    "    # Global random restarts\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(lambda xx: acq(xx), x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    # Local starts near seeds\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(8):\n",
    "                x0 = seed + 0.03 * np.random.randn(5)\n",
    "                x0 = np.clip(x0, 0, 1)\n",
    "                res = minimize(lambda xx: acq(xx), x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# === Identify current best input from dataset ===\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# === Generate next candidates ===\n",
    "x_next_EI = optimize_acq(expected_improvement, local_seeds=[x_best], n_restarts=50)\n",
    "x_next_UCB = optimize_acq(lambda xx: ucb(xx, kappa=3.0), local_seeds=None, n_restarts=40)\n",
    "\n",
    "print(\"Next exploitative EI candidate:\", x_next_EI)\n",
    "print(\"Next exploratory UCB candidate:\", x_next_UCB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_EI, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Focus on improving the current best (-0.7143) by refining the local neighborhood around the best-known recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "- this new sample (-1.5085) is better than many recent poor probes but still far from the best so far (-0.7143). It confirms that its neighborhood is only moderately bad\n",
    "- Best observed: -0.7143 (much better / less negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "\n",
    "x_new6 = np.array([0.362488, 0.030495, 0.284038, 0.329972, 0.326837])   # most recent\n",
    "y_new6 = -1.4257489720250607\n",
    "\n",
    "x_new7 = np.array([0.073946, 0.156948, 0.775064, 0.915405, 0.764599])\n",
    "y_new7 = -1.5084657742366825\n",
    "#\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5, x_new6, x_new7])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5, y_new6, y_new7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Acquisition functions ===\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization\n",
    "\n",
    "def ucb(x, kappa=3.0):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative for minimization\n",
    "\n",
    "bounds = [(0,1)]*5\n",
    "\n",
    "# === Optimizer with global restarts and optional local seeds ===\n",
    "def optimize_acq(acq, local_seeds=None, n_restarts=40):\n",
    "    best_x = None\n",
    "    best_val = float('inf')\n",
    "\n",
    "    # Global random restarts\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(lambda xx: acq(xx),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Local exploration around seeds\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(10):\n",
    "                x0 = seed + 0.03*np.random.randn(5)\n",
    "                x0 = np.clip(x0, 0, 1)\n",
    "                res = minimize(lambda xx: acq(xx),\n",
    "                               x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "# === Identify current best input from dataset ===\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# === Generate next candidates ===\n",
    "x_next_EI = optimize_acq(expected_improvement,\n",
    "                         local_seeds=[x_best],\n",
    "                         n_restarts=50)\n",
    "\n",
    "x_next_UCB = optimize_acq(lambda xx: ucb(xx, kappa=3.0),\n",
    "                          local_seeds=None,\n",
    "                          n_restarts=40)\n",
    "\n",
    "print(\"Next EI (exploitative) candidate:\", x_next_EI)\n",
    "print(\"Next UCB (exploratory) candidate:\", x_next_UCB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_EI, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "- This new output (-1.3619) is better than most recent poor probes, but still well below the best initial point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "\n",
    "x_new6 = np.array([0.362488, 0.030495, 0.284038, 0.329972, 0.326837])   # most recent\n",
    "y_new6 = -1.4257489720250607\n",
    "\n",
    "x_new7 = np.array([0.073946, 0.156948, 0.775064, 0.915405, 0.764599])\n",
    "y_new7 = -1.5084657742366825\n",
    "\n",
    "x_new8 = np.array([0.582955, 0.582660, 0.125772, 0.719076, 0.553669])\n",
    "y_new8 = -1.3618789998515646 \n",
    "#\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5, x_new6, x_new7, x_new8])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5, y_new6, y_new7, y_new8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "- Focus on refining near the best-known recipe (-0.7143), with small xi (0.005‚Äì0.01).\n",
    "- return both the next EI (exploitative) candidate and UCB (exploratory) candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Load existing dataset ===\n",
    "X = np.load(\"initial_inputs.npy\")\n",
    "y = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "# === Append newest observed point ===\n",
    "x_new = np.array([0.582955, 0.582660, 0.125772, 0.719076, 0.553669])\n",
    "y_new = -1.3618789998515646\n",
    "\n",
    "X = np.vstack([X, x_new])\n",
    "y = np.append(y, y_new)\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Acquisition functions ===\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1,-1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimise\n",
    "\n",
    "def ucb(x, kappa=3.0):\n",
    "    x = np.array(x).reshape(1,-1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    return -(mu + kappa * sigma)  # minimise\n",
    "\n",
    "bounds = [(0,1)] * 5\n",
    "\n",
    "# === Generic optimizer ===\n",
    "def optimize_acq(acq, local_seeds=None, n_restarts=40):\n",
    "    best_x, best_val = None, float(\"inf\")\n",
    "\n",
    "    # Global random restarts\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(lambda xx: acq(xx), x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Local restarts near good region\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(10):\n",
    "                x0 = seed + 0.03 * np.random.randn(5)\n",
    "                x0 = np.clip(x0, 0, 1)\n",
    "                res = minimize(lambda xx: acq(xx), x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "# === Identify best observed point ===\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# === Generate next candidates ===\n",
    "x_next_EI = optimize_acq(expected_improvement,\n",
    "                         local_seeds=[x_best],\n",
    "                         n_restarts=50)\n",
    "\n",
    "x_next_UCB = optimize_acq(lambda xx: ucb(xx, kappa=3.0),\n",
    "                          local_seeds=None,\n",
    "                          n_restarts=40)\n",
    "\n",
    "print(\"Next EI (exploitative) candidate:\", x_next_EI)\n",
    "print(\"Next UCB (exploratory) candidate:\", x_next_UCB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Next point (6 dp):\", np.round(x_next_EI, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "- New point: [0.658192, 0.165022, 0.387953, 0.093969, 0.488913] -> -1.793490117932013\n",
    "- new point is poor, and in fact among the worse recent probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "\n",
    "x_new6 = np.array([0.362488, 0.030495, 0.284038, 0.329972, 0.326837])   # most recent\n",
    "y_new6 = -1.4257489720250607\n",
    "\n",
    "x_new7 = np.array([0.073946, 0.156948, 0.775064, 0.915405, 0.764599])\n",
    "y_new7 = -1.5084657742366825\n",
    "\n",
    "x_new8 = np.array([0.582955, 0.582660, 0.125772, 0.719076, 0.553669])\n",
    "y_new8 = -1.3618789998515646 \n",
    "\n",
    "x_new9 = np.array([0.658192, 0.165022, 0.387953, 0.093969, 0.488913])\n",
    "y_new9 = -1.793490117932013\n",
    "\n",
    "#\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5, x_new6, x_new7, x_new8, x_new9])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5, y_new6, y_new7, y_new8, y_new9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "- We have one very strong region (the original best around -0.71).\n",
    "- Many EI and random probes land in the ‚Äúmoderately bad‚Äù band (-1.3 to -1.8).\n",
    "- Some regions are consistently terrible (<-1.9).\n",
    "- This point confirms another bad basin, strengthens the GP‚Äôs global picture, and means the optimisation should now focus almost entirely on very local refinement around the best-known recipe\n",
    "- EI exploration parameter reduced\n",
    "- Local perturbation radius reduced (make very small changes around the current best recipe instead of jumping far away in the input space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Expected Improvement (more exploitative) ===\n",
    "def expected_improvement(x, xi=0.003):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimise for scipy\n",
    "\n",
    "bounds = [(0,1)] * 5\n",
    "\n",
    "# === Acquisition optimiser (tight local trust region) ===\n",
    "def optimize_ei(local_seeds, n_global=30, n_local=15, local_sigma=0.015):\n",
    "    best_x, best_val = None, float(\"inf\")\n",
    "\n",
    "    # --- Global restarts (reduced importance) ---\n",
    "    for _ in range(n_global):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(expected_improvement, x0,\n",
    "                       bounds=bounds, method=\"L-BFGS-B\")\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_x, best_val = res.x, res.fun\n",
    "\n",
    "    # --- Tight local refinements ---\n",
    "    for seed in local_seeds:\n",
    "        for _ in range(n_local):\n",
    "            x0 = seed + local_sigma * np.random.randn(5)\n",
    "            x0 = np.clip(x0, 0, 1)\n",
    "            res = minimize(expected_improvement, x0,\n",
    "                           bounds=bounds, method=\"L-BFGS-B\")\n",
    "            if res.success and res.fun < best_val:\n",
    "                best_x, best_val = res.x, res.fun\n",
    "\n",
    "    return best_x\n",
    "\n",
    "# === Identify best observed point ===\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# === Generate next exploitative candidate ===\n",
    "x_next_EI = optimize_ei(\n",
    "    local_seeds=[x_best],\n",
    "    n_global=30,\n",
    "    n_local=20,\n",
    "    local_sigma=0.015\n",
    ")\n",
    "\n",
    "print(\"Next tightly exploitative EI candidate:\", x_next_EI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(x_next_EI, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
