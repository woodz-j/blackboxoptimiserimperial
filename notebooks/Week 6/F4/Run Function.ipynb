{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Initial data ---\n",
    "#X_init = np.array([...])  # your 30x4 array\n",
    "#y_init = np.array([...])  # your 30 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "# --- Transform to maximization ---\n",
    "y_trans = -y_init\n",
    "y_best = y_trans.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_trans)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we minimize in scipy\n",
    "# --- Expected Improvement acquisition function ---\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "bounds = [(0,1), (0,1), (0,1), (0,1)]\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# Multiple random starts to avoid local maxima\n",
    "for _ in range(20):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "# --- Transform to maximization ---\n",
    "y_trans = -y_init\n",
    "y_best = y_trans.max()\n",
    "\n",
    "\n",
    "# Add the new observation\n",
    "X_new = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])\n",
    "y_new = np.array([-43.88421604431158])\n",
    "\n",
    "# Combine with previous data\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])\n",
    "\n",
    "X_init = X_all\n",
    "y_init = y_all\n",
    "\n",
    "print(X_init)\n",
    "print(y_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transform to maximization (all values consistent) ---\n",
    "y_trans_init = -y_init\n",
    "y_new_trans = -y_new  # transform new point too\n",
    "\n",
    "# --- Combine old + new data ---\n",
    "X = np.vstack([X_init, x_new.reshape(1, -1)])\n",
    "y = np.hstack([y_trans_init, y_new_trans])\n",
    "\n",
    "# --- Current best ---\n",
    "y_best = y.max()\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "print(y_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we minimize in scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Bounds ---\n",
    "bounds = [(0, 1)] * 4\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "for _ in range(15):\n",
    "    # Random start in full space for exploration\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "for _ in range(5):\n",
    "    # Random start near previous best for exploitation\n",
    "    x0 = x_new + np.random.normal(0, 0.05, size=4)\n",
    "    x0 = np.clip(x0, 0, 1)  # ensure within bounds\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Next hyperparameter set to try:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Original dataset (30 initial points) ---\n",
    "X_init = np.array([...])  # 30x4 array of initial hyperparameters\n",
    "y_init = np.array([...])  # 30 original outputs (negative)\n",
    "\n",
    "# --- Previous week's best point ---\n",
    "X_prev_week = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])\n",
    "y_prev_week = np.array([-43.88421604431158])  # original output\n",
    "\n",
    "# --- Latest evaluation ---\n",
    "X_new = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])\n",
    "y_new = np.array([-53.93723834447932])  # original output\n",
    "\n",
    "# --- Combine all points ---\n",
    "X = np.vstack([X_init, X_prev_week, X_new])\n",
    "y = np.hstack([y_init, y_prev_week, y_new])\n",
    "\n",
    "# --- Transform to maximization for GP ---\n",
    "y_trans = -y  # all negative outputs become positive for GP\n",
    "\n",
    "# --- Current best ---\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize in scipy\n",
    "\n",
    "# --- Bounds ---\n",
    "bounds = [(0, 1)] * 4\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# 1️⃣ Exploitation: many starts near the last best point for fine refinement\n",
    "for _ in range(10):\n",
    "    x0 = X_new[0] + np.random.normal(0, 0.02, size=4)  # small noise\n",
    "    x0 = np.clip(x0, 0, 1)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2️⃣ Exploration: a few random starts to cover the rest of the space\n",
    "for _ in range(5):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Original dataset (30 initial points) ---\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "print(X_init)\n",
    "print(y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Summary\n",
    "All historical points are included:\n",
    "30 initial points\n",
    "Previous week’s best (-43.88)\n",
    "Latest extreme point (-53.93)\n",
    "Consistent transformation: y_trans = -y\n",
    "Focus on fine-grained exploitation near the current extreme point (X_new)\n",
    "Small exploratory starts remain to avoid missing other potential peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Original dataset (30 initial points) ---\n",
    "# X_init = np.array([...])  # (30, 4)\n",
    "# y_init = np.array([...])  # (30,)\n",
    "\n",
    "# --- Previous high-performing points ---\n",
    "X_prev_week = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])  # week 1\n",
    "y_prev_week = np.array([-43.88421604431158])\n",
    "\n",
    "X_new = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])        # week 2\n",
    "y_new = np.array([-53.93723834447932])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X_init, X_prev_week, X_new])\n",
    "y = np.hstack([y_init, y_prev_week, y_new])\n",
    "\n",
    "# --- Transform for maximization (GP expects to maximize) ---\n",
    "y_trans = -y  # make outputs positive\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.02):  # <-- slightly higher xi\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization\n",
    "\n",
    "# --- Bounds (stay slightly inside [0,1]) ---\n",
    "epsilon = 0.01\n",
    "bounds = [(0, 1 - epsilon)] * 4\n",
    "\n",
    "# --- Optimize the acquisition function ---\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# 1️⃣ Local search around the last strong point (exploitation)\n",
    "for _ in range(10):\n",
    "    x0 = X_new[0] + np.random.normal(0, 0.02, size=4)\n",
    "    x0 = np.clip(x0, epsilon, 1 - epsilon)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2️⃣ Broader search to maintain exploration\n",
    "for _ in range(5):\n",
    "    x0 = np.random.rand(4) * (1 - 2*epsilon) + epsilon\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Next hyperparameter set to try:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "<!-- You tested [0.99,0.99,0.99,0.99] → result -53.5903.\n",
    "Your best so far remains -53.9372 at [0.999999,0.999999,0.999999,0.956184].\n",
    "So moving slightly inside on all dims produced a slight degradation (worse than the best).\n",
    "That suggests the true optimum is closer to the previous extreme point, and that the 4th dimension (≈0.956) may be important\n",
    "it’s not best at 0.99 in that coordinate. The surface seems peaked near the previous best. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Original dataset (30 initial points) ---\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# --- Previous high-performing points ---\n",
    "X_week1 = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])  # week 1\n",
    "y_week1 = np.array([-43.88421604431158])\n",
    "\n",
    "X_week2 = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])        # week 2\n",
    "y_week2 = np.array([-53.93723834447932])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X_init, X_week1, X_week2])\n",
    "y = np.hstack([y_init, y_week1, y_week2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.990000, 0.990000, 0.990000, 0.990000]])        # week 3\n",
    "y_new = np.array([-53.590344373442626])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X, X_new])\n",
    "y = np.hstack([y, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Tweak to xi only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transform for maximization (GP expects to maximize) ---\n",
    "y_trans = -y  # make outputs positive\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.002):  # <-- lower\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization\n",
    "\n",
    "# --- Bounds (stay slightly inside [0,1]) ---\n",
    "epsilon = 0.01\n",
    "bounds = [(0, 1 - epsilon)] * 4\n",
    "\n",
    "# --- Optimize the acquisition function ---\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# 1️⃣ Local search around the last strong point (exploitation)\n",
    "for _ in range(10):\n",
    "    x0 = X_new[0] + np.random.normal(0, 0.02, size=4)\n",
    "    x0 = np.clip(x0, epsilon, 1 - epsilon)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2️⃣ Broader search to maintain exploration\n",
    "for _ in range(5):\n",
    "    x0 = np.random.rand(4) * (1 - 2*epsilon) + epsilon\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Keeps all data so far\n",
    "✅ Penalizes EI near the edges\n",
    "✅ Uses safe interior bounds (ε = 1e-3)\n",
    "✅ Selects a single next point for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Existing data -------------------------------------------------------------\n",
    "# X_init: 30x4 initial inputs\n",
    "# y_init: 30 outputs\n",
    "# (Paste your original arrays here)\n",
    "# Example placeholders:\n",
    "# X_init = np.array([...])\n",
    "# y_init = np.array([...])\n",
    "\n",
    "# --- Previous weeks' results ---------------------------------------------------\n",
    "# X_prev_week = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])\n",
    "# y_prev_week = np.array([-43.88421604431158])\n",
    "\n",
    "# X_new = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])\n",
    "# y_new = np.array([-53.93723834447932])\n",
    "\n",
    "# X_recent = np.array([[0.99, 0.99, 0.99, 0.99]])\n",
    "# y_recent = np.array([-53.590344373442626])\n",
    "\n",
    "# # --- Combine all data ----------------------------------------------------------\n",
    "# X = np.vstack([X_init, X_prev_week, X_new, X_recent])\n",
    "# y = np.hstack([y_init, y_prev_week, y_new, y_recent])\n",
    "\n",
    "# --- Transform for maximization (since y are losses) ---------------------------\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# --- Fit Gaussian Process -----------------------------------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# --- Parameters for safe bounds -----------------------------------------------\n",
    "epsilon = 1e-3\n",
    "lower, upper = epsilon, 1.0 - epsilon\n",
    "bounds = [(lower, upper)] * 4\n",
    "\n",
    "# --- Penalized Expected Improvement function ----------------------------------\n",
    "def expected_improvement_penalized(x, gp, y_best, xi=0.002, penalty_scale=0.05):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma < 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    # --- boundary penalty ---\n",
    "    closeness = np.minimum(x - lower, upper - x)\n",
    "    penalty = penalty_scale * np.sum(1.0 / (closeness + 1e-6))\n",
    "    return -(ei - penalty)  # negative for minimization\n",
    "\n",
    "# --- Optimization setup -------------------------------------------------------\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# set X_recent\n",
    "X_recent = X_new\n",
    "# 1️⃣ Exploitation: search near latest best region, avoid edges\n",
    "x_center = X_recent[0]\n",
    "for _ in range(10):\n",
    "    x0 = x_center + np.random.normal(0, 0.02, size=4)\n",
    "    x0 = np.clip(x0, lower, upper)\n",
    "    res = minimize(lambda x: expected_improvement_penalized(x, gp, y_best, xi=0.005),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2️⃣ Exploration: random restarts to probe other regions\n",
    "for _ in range(5):\n",
    "    x0 = np.random.uniform(lower, upper, 4)\n",
    "    res = minimize(lambda x: expected_improvement_penalized(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# --- Result -------------------------------------------------------------------\n",
    "x_next = np.clip(best_x, lower, upper)\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement slight tweak\n",
    "# It keeps the same structure but slightly reduces boundary penalties and biases the optimizer back toward near-edge refinement\n",
    "# while still allowing global exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Existing data -------------------------------------------------------------\n",
    "# (Paste your original arrays here)\n",
    "# X_init = np.array([...])\n",
    "# y_init = np.array([...])\n",
    "\n",
    "# --- Transform for maximization -----------------------------------------------\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# --- Fit Gaussian Process -----------------------------------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# --- Safe bounds ---------------------------------------------------------------\n",
    "epsilon = 1e-3\n",
    "lower, upper = epsilon, 1.0 - epsilon\n",
    "bounds = [(lower, upper)] * 4\n",
    "\n",
    "# --- Penalized Expected Improvement -------------------------------------------\n",
    "def expected_improvement_penalized(x, gp, y_best, xi=0.001, penalty_scale=0.02):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma < 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    # boundary penalty: weaker than before\n",
    "    closeness = np.minimum(x - lower, upper - x)\n",
    "    penalty = penalty_scale * np.sum(1.0 / (closeness + 1e-6))\n",
    "    return -(ei - penalty)  # negate for minimization\n",
    "\n",
    "# --- Optimize acquisition function --------------------------------------------\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# set X_recent\n",
    "X_recent = X_new\n",
    "\n",
    "# 1️⃣ Exploitation: more local restarts near the recent high-performing point\n",
    "x_center = X_recent[0]\n",
    "for _ in range(20):  # increased from 10\n",
    "    x0 = x_center + np.random.normal(0, 0.015, size=4)\n",
    "    x0 = np.clip(x0, lower, upper)\n",
    "    res = minimize(lambda x: expected_improvement_penalized(x, gp, y_best,\n",
    "                                                           xi=0.001,\n",
    "                                                           penalty_scale=0.02),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2️⃣ Exploration: a few global random restarts\n",
    "for _ in range(5):\n",
    "    x0 = np.random.uniform(lower, upper, 4)\n",
    "    res = minimize(lambda x: expected_improvement_penalized(x, gp, y_best,\n",
    "                                                           xi=0.001,\n",
    "                                                           penalty_scale=0.02),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# --- Result -------------------------------------------------------------------\n",
    "x_next = np.clip(best_x, lower, upper)\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it still moves toward midspace, it’s a sign the GP is confident the corner is saturated\n",
    "# which would be valuable information for your next model iteration.\n",
    "# This will compute EI without boundary penalty but keep a tiny interior epsilon so you get a proper refinement candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes gp, X, y_trans already defined as in your pipeline\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "epsilon = 1e-6\n",
    "bounds_edge = [(epsilon, 1-epsilon)]*4\n",
    "\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.array(x).reshape(1,-1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = max(sigma[0], 1e-12)\n",
    "    imp = mu[0] - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    return -(imp * norm.cdf(Z) + sigma * norm.pdf(Z))  # negative for minimizer\n",
    "\n",
    "# center of last-best and small jitter\n",
    "center = np.array([0.999999, 0.999999, 0.999999, 0.956184])\n",
    "best_x = None\n",
    "best_val = 1e9\n",
    "for _ in range(50):             # many local starts to refine\n",
    "    x0 = center + np.random.normal(0, 0.005, 4)\n",
    "    x0 = np.clip(x0, epsilon, 1-epsilon)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_trans.max(), xi=0.0005),\n",
    "                   x0=x0, bounds=bounds_edge, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"Suggested near-edge candidate:\", best_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# The last few iterations have heavily focused on the boundary — all near [1,1,1,~0.95+].\n",
    "# The model is now overconfident near that edge and has high uncertainty elsewhere.\n",
    "# Evaluating the center gives the GP new information in an unexplored region, which helps recalibrate its uncertainty estimates.\n",
    "# This is healthy exploration, preventing premature convergence on what might be a misleading edge optimum.\n",
    "# I will stick with [0.49999999 0.5        0.5        0.49999999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "# --- Original dataset (30 initial points) ---\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# --- Previous high-performing points ---\n",
    "X_week1 = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])  # week 1\n",
    "y_week1 = np.array([-43.88421604431158])\n",
    "\n",
    "X_week2 = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])        # week 2\n",
    "y_week2 = np.array([-53.93723834447932])\n",
    "\n",
    "X_week3 = np.array([[0.990000, 0.990000, 0.990000, 0.990000]])        # week 3\n",
    "y_week3 = np.array([-53.590344373442626])\n",
    "\n",
    "X_week4 = np.array([[0.499999, 0.500000, 0.500000, 0.499999]])        # week 4\n",
    "y_week4 = np.array([-3.9857608859098153])\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X_init, X_week1, X_week2, X_week3, X_week4])\n",
    "y = np.hstack([y_init, y_week1, y_week2, y_week3, y_week4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "- The new center point [0.5, 0.5, 0.5, 0.5] produced -3.9858, which is much worse than your best-known results (best so far -53.9372).\n",
    "- This strongly confirms that the high-performing region is at the upper corner (near the previously tested points ~[1,1,1,~0.95])\n",
    "- and not in the center of the space. The center is a poor region for the objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fit Gaussian Process -----------------------------------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "\n",
    "# assume X, y include the center point; y are original negatives\n",
    "y_trans = -y\n",
    "gp.fit(X, y_trans)\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# exploit-local refinement around current best\n",
    "center = np.array([0.999999,0.999999,0.999999,0.956184])\n",
    "cand_list = np.array([\n",
    "    center + np.array([0,0,0, delta]) for delta in [0.002, 0.004, -0.004, 0.0005]\n",
    "])\n",
    "cand_list = np.clip(cand_list, 0, 1)\n",
    "\n",
    "# score by EI\n",
    "from scipy.stats import norm\n",
    "def ei(x):\n",
    "    mu, sigma = gp.predict(x.reshape(1,-1), return_std=True)\n",
    "    if sigma[0] < 1e-12: return 0.0\n",
    "    imp = mu[0] - y_best - 0.001\n",
    "    Z = imp / sigma[0]\n",
    "    return imp * norm.cdf(Z) + sigma[0] * norm.pdf(Z)\n",
    "\n",
    "scores = [ei(c) for c in cand_list]\n",
    "best_idx = int(np.argmax(scores))\n",
    "x_next = cand_list[best_idx]\n",
    "print(\"Suggested next (exploit) candidate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "- The latest point -54.03 improves slightly over the previous best -53.937.\n",
    "- The high-performing region is now confirmed at the upper corner, especially the last dimension around 0.956–0.960.\n",
    "- Incrementing the last coordinate from 0.956184 → 0.960184 gives a small but measurable improvement (-53.94 → -54.03).\n",
    "- Suggests the optimum may be slightly above 0.960.\n",
    "- First three dimensions are effectively saturated at 1.0. No gain expected by tweaking them further.\n",
    "- Exploitation-focused refinement in the 4th dimension is now appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "# --- Original dataset (30 initial points) ---\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# --- Previous high-performing points ---\n",
    "X_week1 = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])  # week 1\n",
    "y_week1 = np.array([-43.88421604431158])\n",
    "\n",
    "X_week2 = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])        # week 2\n",
    "y_week2 = np.array([-53.93723834447932])\n",
    "\n",
    "X_week3 = np.array([[0.990000, 0.990000, 0.990000, 0.990000]])        # week 3\n",
    "y_week3 = np.array([-53.590344373442626])\n",
    "\n",
    "X_week4 = np.array([[0.499999, 0.500000, 0.500000, 0.499999]])        # week 4\n",
    "y_week4 = np.array([-3.9857608859098153])\n",
    "\n",
    "X_week5 = np.array([[0.999999, 0.999999, 0.999999, 0.960184]])        # week 5\n",
    "y_week5 = np.array([-54.03075969006948])\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X_init, X_week1, X_week2, X_week3, X_week4, X_week5])\n",
    "y = np.hstack([y_init, y_week1, y_week2, y_week3, y_week4, y_week5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(\"------------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Since the first three dimensions are effectively saturated at 1.0, we only need to refine the 4th dimension in small steps around the current best (0.960184)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Assume your existing data is in X, y ---\n",
    "# Example placeholders:\n",
    "# X = np.vstack([X_init, previous points...])\n",
    "# y = np.hstack([y_init, previous outputs...])\n",
    "\n",
    "# Transform for maximization\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# Fit Gaussian Process\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# Expected Improvement function\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = max(sigma[0], 1e-12)\n",
    "    imp = mu[0] - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "# --- Generate candidate points along 4th dimension ---\n",
    "best_corner = np.array([1.0, 1.0, 1.0, 0.960184])\n",
    "d4_steps = np.array([0.961, 0.962, 0.963, 0.964, 0.965, 0.966])  # next fine steps\n",
    "\n",
    "candidates = np.array([np.hstack([best_corner[:3], d4]) for d4 in d4_steps])\n",
    "\n",
    "# --- Score candidates using EI ---\n",
    "ei_scores = np.array([expected_improvement(x, gp, y_best) for x in candidates])\n",
    "\n",
    "# --- Rank candidates ---\n",
    "rank_idx = np.argsort(-ei_scores)  # descending order\n",
    "top_candidates = candidates[rank_idx]\n",
    "top_ei = ei_scores[rank_idx]\n",
    "\n",
    "# Print results\n",
    "for i, (cand, score) in enumerate(zip(top_candidates, top_ei), 1):\n",
    "    print(f\"Rank {i}: Candidate = {cand}, EI = {score:.6f}\")\n",
    "\n",
    "# Suggested next point\n",
    "x_next = top_candidates[0]\n",
    "print(\"\\nSuggested next evaluation point:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
