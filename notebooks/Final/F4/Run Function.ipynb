{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 13\n",
    "- The output is far worse than the best corner values (~ −55.8).\n",
    "- Even with fairly high values in dimensions 3 and 4, performance collapses when dimensions 1 and 2 are moderate.\n",
    "- This reinforces the finding that all dimensions must be jointly high to achieve strong performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "# --- Original dataset (30 initial points) ---\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# --- Previous high-performing points ---\n",
    "X_week1 = np.array([[0.999999, 0.999999, 0.910203, 0.738695]])  # week 1\n",
    "y_week1 = np.array([-43.88421604431158])\n",
    "\n",
    "X_week2 = np.array([[0.999999, 0.999999, 0.999999, 0.956184]])        # week 2\n",
    "y_week2 = np.array([-53.93723834447932])\n",
    "\n",
    "X_week3 = np.array([[0.990000, 0.990000, 0.990000, 0.990000]])        # week 3\n",
    "y_week3 = np.array([-53.590344373442626])\n",
    "\n",
    "X_week4 = np.array([[0.499999, 0.500000, 0.500000, 0.499999]])        # week 4\n",
    "y_week4 = np.array([-3.9857608859098153])\n",
    "\n",
    "X_week5 = np.array([[0.999999, 0.999999, 0.999999, 0.960184]])        # week 5\n",
    "y_week5 = np.array([-54.03075969006948])\n",
    "\n",
    "X_week6 = np.array([[0.999999, 0.999999, 0.999999, 0.966000]])        # week 6\n",
    "y_week6 = np.array([-54.191444279951604])\n",
    "\n",
    "X_week7 = np.array([[0.999999, 0.999999, 0.999999, 0.972000]])        # week 7\n",
    "y_week7 = np.array([-54.393239979988984])\n",
    "\n",
    "X_week8 = np.array([[0.999999, 0.999999, 0.999999, 0.990000]])        # week 8\n",
    "y_week8 = np.array([-55.23213675850386])\n",
    "\n",
    "X_week9 = np.array([[0.999999, 0.999999, 0.999999, 0.999999]])        # week 9\n",
    "y_week9 = np.array([-55.827686352381896])\n",
    "\n",
    "X_week10 = np.array([[0.355683, 0.539378, 0.969965, 0.296923]])        # week 10\n",
    "y_week10 = np.array([-17.272166117748323])\n",
    "\n",
    "X_week11 = np.array([[0.017062, 0.357698, 0.384798, 0.666174]])        # week 11\n",
    "y_week11 = np.array([-12.420814399410862])\n",
    "\n",
    "X_week12 = np.array([[0.233771, 0.405444, 0.820900, 0.846825]])        # week 12\n",
    "y_week12 = np.array([-19.67662418731153])\n",
    "# --- Combine all data ---\n",
    "X = np.vstack([X_init, X_week1, X_week2, X_week3, X_week4, X_week5, X_week6, X_week7, X_week8, X_week9, X_week10, X_week11, X_week12])\n",
    "y = np.hstack([y_init, y_week1, y_week2, y_week3, y_week4, y_week5, y_week6, y_week7, y_week8, y_week9, y_week10, y_week11, y_week12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# X, y now include ALL evaluations (including the final one)\n",
    "y_trans = -y\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=Matern(nu=2.5),\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "\n",
    "gp.fit(X, y_trans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "- Sensitivity check around the optimum\n",
    "- Shows which dimensions matter\n",
    "- Confirm no hidden interior optimum remains.\n",
    "- After adding the final data point, the optimisation phase is complete; the remaining code should only refit the surrogate and analyse sensitivity and robustness of the discovered optimum.\n",
    "- If this does not beat the corner, we’re done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner = np.array([0.999, 0.999, 0.999, 0.999])\n",
    "\n",
    "deltas = np.linspace(0.7, 1.0, 7)\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"\\nVarying dimension {i}:\")\n",
    "    for d in deltas:\n",
    "        x = corner.copy()\n",
    "        x[i] = d\n",
    "        mu, sigma = gp.predict(x.reshape(1,-1), return_std=True)\n",
    "        print(f\"x={x}, predicted={-mu[0]:.2f}, uncertainty={sigma[0]:.3f}\")\n",
    "\n",
    "# Confirm no hidden interior optimum remains.\n",
    "\n",
    "X_rand = np.random.uniform(0, 1, size=(2000, 4))\n",
    "mu, _ = gp.predict(X_rand, return_std=True)\n",
    "\n",
    "best_idx = np.argmax(mu)\n",
    "print(\"Best predicted interior point:\", X_rand[best_idx])\n",
    "print(\"Predicted value:\", -mu[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(X_rand[best_idx], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- Best known region (full corner): ≈ −55.8\n",
    "- Strong near-corner points (3 dims ≈ 1, 1 slightly lower): ≈ −53 to −54\n",
    "- This point: −41.15\n",
    "- That’s a large drop (≈ +14 in loss) from the optimum.\n",
    "The near-corner evaluation at [0.927,0.990,0.947,0.715] resulted in a substantially weaker outcome than the full corner, confirming that the objective exhibits a steep, interaction-driven optimum rather than a broad plateau. Even a single reduced dimension leads to a large performance drop.\n",
    "- possibly found the true optimum region\n",
    "- Continued exploration away from the corner is not beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
