{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Week 13\n",
    "Best result so far (9.9763) This is a clear improvement over your previous best (~9.95), which shows that the recent exploit step successfully refined the dominant peak rather than just hovering around it.\n",
    "High-performing points consistently show:\n",
    "- low but non-zero values in the early dimensions,\n",
    "- mid-range values in dimensions 4 and 8,\n",
    "- high (but not extreme) values in dimension 5, and\n",
    "- moderate values in dimension 6.\n",
    "- This point fits that pattern almost perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Load initial dataset\n",
    "# ---------------------------------------------------\n",
    "datain = np.load(\"initial_inputs.npy\")\n",
    "dataout = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Append ALL previously evaluated points\n",
    "# ---------------------------------------------------\n",
    "new_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000],\n",
    "    [0.054679, 0.080603, 0.022102, 0.068388, 0.990000, 0.427374, 0.138631, 0.010000],\n",
    "    [0.045771, 0.336234, 0.012812, 0.225992, 0.741620, 0.506746, 0.173188, 0.640432],\n",
    "    [0.129989, 0.237128, 0.115863, 0.170000, 0.830000, 0.407575, 0.138631, 0.170000],\n",
    "    [0.204502, 0.182027, 0.035863, 0.106562, 0.750000, 0.397148, 0.125236, 0.250000],\n",
    "    [0.189149, 0.736433, 0.210576, 0.144803, 0.708952, 0.282470, 0.128724, 0.421223],\n",
    "    [0.116284, 0.212414, 0.105883, 0.174974, 0.814110, 0.434712, 0.187492, 0.250000]\n",
    "])\n",
    "\n",
    "new_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899,\n",
    "    9.883822772355,\n",
    "    9.9091106001996,\n",
    "    9.95459577812,\n",
    "    9.913402905816,\n",
    "    9.5558759359951,\n",
    "    9.976280596427\n",
    "])\n",
    "\n",
    "X_all = np.vstack([X_all, new_points])\n",
    "y_all = np.hstack([y_all, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "- Perform a micro-refinement around the current best\n",
    "- Assume you are already at the peak\n",
    "- Reduce step size, remove exploration completely\n",
    "- Shrink the local radius\n",
    "- Keep mean-based exploitation\n",
    "- Reduce restarts (optional but cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Fit GP surrogate\n",
    "# ---------------------------------------------------\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(\n",
    "    length_scale=np.ones(dim),\n",
    "    length_scale_bounds=(1e-2, 1e2),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "\n",
    "def neg_mean(x, gp):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu = gp.predict(x)\n",
    "    return -mu[0]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Expected Improvement\n",
    "# ---------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    improvement = mu - y_best - xi\n",
    "    Z = improvement / sigma\n",
    "    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi)[0]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Acquisition optimizer\n",
    "# ---------------------------------------------------\n",
    "def propose_exploit_location(gp, bounds, n_restarts=30):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_mean,\n",
    "            x0=x0,\n",
    "            args=(gp,),\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\",\n",
    "            options={\"maxiter\": 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return np.clip(best_x, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. EXPLOIT candidate (local, low xi)\n",
    "# ---------------------------------------------------\n",
    "# local_radius = 0.08\n",
    "local_radius = 0.03\n",
    "eps = 1e-3\n",
    "\n",
    "exploit_bounds = []\n",
    "for i in range(dim):\n",
    "    if x_best[i] <= 0.02 or x_best[i] >= 0.98:\n",
    "        low = max(eps, x_best[i] - 0.02)\n",
    "        high = min(1 - eps, x_best[i] + 0.02)\n",
    "    else:\n",
    "        low = max(eps, x_best[i] - local_radius)\n",
    "        high = min(1 - eps, x_best[i] + local_radius)\n",
    "    exploit_bounds.append((low, high))\n",
    "\n",
    "exploit_bounds = np.array(exploit_bounds)\n",
    "\n",
    "x_exploit = propose_exploit_location(\n",
    "    gp,\n",
    "    exploit_bounds,\n",
    "    n_restarts=20\n",
    ")\n",
    "\n",
    "# x_exploit = propose_location(\n",
    "#     gp,\n",
    "#     y_best,\n",
    "#     exploit_bounds,\n",
    "#     xi=0.001,\n",
    "#     n_restarts=30\n",
    "# )\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Results\n",
    "# ---------------------------------------------------\n",
    "print(\"Current best y:\", y_best)\n",
    "print(\"Current best x:\", x_best)\n",
    "print(\"\\nNext EXPLOIT candidate:\", x_exploit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_exploit, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- New best (9.9835)\n",
    "This is a small but meaningful improvement over 9.9763, which is precisely the scale of gain you expect when you’re shaving the top of a smooth peak. It confirms there was a little headroom left.\n",
    "- Confirms a broad, smooth optimum\n",
    "The improvement came from very modest parameter shifts, not a jump to a new region. That tells us the maximum is flat and well-behaved, not sharp or noisy.\n",
    "- almost certainly at the top of the dominant peak.\n",
    "- Any further improvement would be within noise or require extremely fine-grained search that isn’t justified.\n",
    "- This point is a textbook convergence confirmation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
