{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "#X_init = ... # 20x5 array\n",
    "#y_init = ... # 20 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Week 13\n",
    "- −1.09 is clearly better than most exploratory points (often −1.5 to −2.0),\n",
    "- But still worse than the current best (~−0.71),\n",
    "- This evaluation strengthens the conclusion that many regions can perform reasonably well, but only one tight region achieves truly strong scores, validating the exploit-focused strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   \n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "x_new5 = np.array([0.179353, 0.275894, 0.945129, 0.233346, 0.440738])   # most recent\n",
    "y_new5 = -1.544891734939286\n",
    "\n",
    "x_new6 = np.array([0.362488, 0.030495, 0.284038, 0.329972, 0.326837])   \n",
    "y_new6 = -1.4257489720250607\n",
    "\n",
    "x_new7 = np.array([0.073946, 0.156948, 0.775064, 0.915405, 0.764599])\n",
    "y_new7 = -1.5084657742366825\n",
    "\n",
    "x_new8 = np.array([0.582955, 0.582660, 0.125772, 0.719076, 0.553669])\n",
    "y_new8 = -1.3618789998515646 \n",
    "\n",
    "x_new9 = np.array([0.658192, 0.165022, 0.387953, 0.093969, 0.488913])\n",
    "y_new9 = -1.793490117932013\n",
    "\n",
    "x_new10 = np.array([0.611533, 0.870172, 0.351305, 0.181109, 0.061446])\n",
    "y_new10 = -1.635316940626951\n",
    "\n",
    "x_new11 = np.array([0.500000, 0.500000, 0.500000, 0.500000, 0.499999])\n",
    "y_new11 = -1.0389035907135546\n",
    "\n",
    "x_new12 = np.array([0.755892, 0.110166, 0.748529, 0.396807, 0.100741])\n",
    "y_new12 = -1.0933788975150396\n",
    "\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4, x_new5, x_new6, x_new7, x_new8, x_new9, x_new10, x_new11, x_new12])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4, y_new5, y_new6, y_new7, y_new8, y_new9, y_new10, y_new11, y_new12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "This point adds confidence that the search space consists of:\n",
    "- One narrow high-performing basin, and a wider region of “okay but not optimal” recipes.\n",
    "\n",
    "The rational next step remains:\n",
    "- Very local exploitation around the best-known point,\n",
    "- Reduce EI exploration pressure further\n",
    "- This version achieves very local exploitation by zeroing EI exploration (xi=0) and concentrating most optimiser starts within a tiny Gaussian neighbourhood around the best-known point, while keeping light global restarts only as a safeguard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Expected Improvement (more exploitative) ===\n",
    "def expected_improvement(x, xi=0.0): # reduce xi to 0\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimise for scipy\n",
    "\n",
    "bounds = [(0,1)] * 5\n",
    "\n",
    "# === Acquisition optimiser (tight local trust region) ===\n",
    "def optimize_ei(local_seeds, n_global=30, n_local=15, local_sigma=0.015):\n",
    "    best_x, best_val = None, float(\"inf\")\n",
    "\n",
    "    # --- Global restarts (reduced importance) ---\n",
    "    for _ in range(n_global):\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(expected_improvement, x0,\n",
    "                       bounds=bounds, method=\"L-BFGS-B\")\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_x, best_val = res.x, res.fun\n",
    "\n",
    "    # --- Tight local refinements ---\n",
    "    for seed in local_seeds:\n",
    "        for _ in range(n_local):\n",
    "            x0 = seed + local_sigma * np.random.randn(5)\n",
    "            x0 = np.clip(x0, 0, 1)\n",
    "            res = minimize(expected_improvement, x0,\n",
    "                           bounds=bounds, method=\"L-BFGS-B\")\n",
    "            if res.success and res.fun < best_val:\n",
    "                best_x, best_val = res.x, res.fun\n",
    "\n",
    "    return best_x\n",
    "\n",
    "# === Identify best observed point ===\n",
    "idx_best = np.argmax(y_trans)\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# === Generate next exploitative candidate ===\n",
    "x_next_EI = optimize_ei(\n",
    "    local_seeds=[x_best],\n",
    "    n_global=10,\n",
    "    n_local=20,\n",
    "    local_sigma=0.015\n",
    ")\n",
    "\n",
    "print(\"Next tightly exploitative EI candidate:\", x_next_EI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNext point to evaluate (6 dp):\", np.round(x_next_EI, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "A score of −1.24 is:\n",
    "- Better than many random or exploratory points (often −1.5 to −2.0),\n",
    "- Clearly worse than the current best (~−0.71),\n",
    "- Slightly worse than the “reasonable interior” points you’ve seen (around −1.0 to −1.1).\n",
    "- This evaluation adds another data point to the “moderate plateau” and strengthens confidence that meaningful gains will only come from tight local refinement near the current best solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
