{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- Initial data ---\n",
    "X_init = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ]\n",
    "])\n",
    "\n",
    "y_init = np.array([0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "                   0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "                   -0.01385762, 0.61120522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new observation\n",
    "X_new = np.array([[0.365139, 0.474667]])\n",
    "y_new = np.array([-0.006080823079048435])\n",
    "\n",
    "# Combine with previous data\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])\n",
    "\n",
    "X_init = X_all\n",
    "y_init = y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_init)\n",
    "print(X_init.shape)   # Useful if it’s an array\n",
    "print(type(X_init)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_init)\n",
    "print(y_init.shape)   # Useful if it’s an array\n",
    "print(type(y_init)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 13\n",
    "- This is by far the best observed value. It has made a large jump from ~0.69 to 0.764.\n",
    "- The peak is very sharp, Very local and slightly offset from your earlier best points\n",
    "- the previous “best” points (≈0.507–0.514) were near but not centered on the maximum.\n",
    "- This micro-jitter step finally landed closer to the true summit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821],\n",
    "    [0.425763, 0.235879],\n",
    "    [0.517484, 0.513827],\n",
    "    [0.521491, 0.517865],\n",
    "    [0.529509, 0.525943],\n",
    "    [0.517812, 0.514158],\n",
    "    [0.750000, 0.950000],\n",
    "    [0.507619, 0.513076],\n",
    "    [0.509245, 0.510513] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272,\n",
    "    0.12646677030059522, \n",
    "    0.5750720845426626,\n",
    "    0.5531590730253101,\n",
    "    0.6221952072714012,\n",
    "    0.649396599976428, \n",
    "    0.40419253487539164,\n",
    "    0.6938072842426951,\n",
    "    0.7637259336235012 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "- This improvement is too large and too structured to be pure noise\n",
    "- Neighbouring points are already high\n",
    "- The jump happened in a consistent direction\n",
    "- The GP length-scale warnings predicted a sharp peak\n",
    "- This is almost certainly closer to the true global maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Summary\n",
    "After identifying a dominant region, we progressively restricted the search space and reduced step sizes. This allowed us to resolve a sharp local maximum that earlier, noisier evaluations had only partially identified, leading to a substantial late-stage improvement.\n",
    "\n",
    "# Final step\n",
    "Ultra-fine micro-jitter around the current best point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Refit GP on ALL available data\n",
    "# --------------------------------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-3,          # noise-aware\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Expected Improvement (unchanged)\n",
    "# --------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "\n",
    "    if sigma < 1e-9:\n",
    "        return 0.0\n",
    "\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Micro-jitter bounds around best observed point\n",
    "# --------------------------------------------------\n",
    "idx_best = np.argmax(y_all)\n",
    "x_best = X_all[idx_best]\n",
    "y_best = y_all[idx_best]\n",
    "\n",
    "# delta = 0.01  # micro-jitter radius (tight exploitation)\n",
    "delta = 0.003 # even tighter\n",
    "\n",
    "bounds_local = [\n",
    "    (max(0.0, x_best[0] - delta), min(1.0, x_best[0] + delta)),\n",
    "    (max(0.0, x_best[1] - delta), min(1.0, x_best[1] + delta)),\n",
    "]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Local acquisition optimization\n",
    "# --------------------------------------------------\n",
    "def propose_location_local(acquisition, gp, y_best, bounds, x_center, n_restarts=20):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = x_center + 0.5 * (np.random.rand(2) - 0.5) * (bounds[0][1] - bounds[0][0])\n",
    "        x0 = np.clip(x0, [b[0] for b in bounds], [b[1] for b in bounds])\n",
    "\n",
    "        res = minimize(\n",
    "            lambda x: acquisition(x, gp, y_best),\n",
    "            x0=x0,\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\"\n",
    "        )\n",
    "\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Generate next micro-jitter point\n",
    "# --------------------------------------------------\n",
    "x_next = propose_location_local(\n",
    "    expected_improvement,\n",
    "    gp,\n",
    "    y_best,\n",
    "    bounds_local,\n",
    "    x_center=x_best\n",
    ")\n",
    "\n",
    "print(\"Next micro-jitter point:\", np.round(x_next, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- Previous best:\n",
    "0.7637259336 at [0.509245, 0.510513]\n",
    "\n",
    "Final micro-jitter result:\n",
    "0.6385091865 at [0.509688, 0.510529]\n",
    "\n",
    "The final point is lower, but this is exactly what we should expect at this stage.\n",
    "\n",
    "- Best observed value:\n",
    "0.7637259336235012\n",
    "\n",
    "At point:\n",
    "[0.509245, 0.510513]\n",
    "- A final micro-jitter evaluation around the best point produced a lower value, indicating that the previous evaluation was already at or extremely close to the local maximum. This confirms convergence rather than suggesting further improvement was available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
