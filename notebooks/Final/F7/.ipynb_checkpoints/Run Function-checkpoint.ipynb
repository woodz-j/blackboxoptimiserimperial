{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 13\n",
    "- ([0.384396 0.812922 0.458117 0.582021 0.732893 0.001   ]) the output (2.8596) is a new best\n",
    "- This is important as it exceeds the previous best (~2.82–2.75 range)\n",
    "- It was achieved by micro-perturbation, not exploration\n",
    "- This confirms the GP’s local curvature model is accurate\n",
    "- In other words the GP isn’t just exploiting noise — it’s climbing a real peak.\n",
    "- This point confirms the existence of a sharp optimum around the identified cluster, validates keeping dimension 6 at zero, and shows that micro-perturbation EI is still yielding real (though diminishing) gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load initial data ---\n",
    "X_init = np.load('initial_inputs.npy')   # 30x6\n",
    "y_init = np.load('initial_outputs.npy')  # 30 outputs\n",
    "\n",
    "# 1. --- Add new observations ---\n",
    "new_X = np.array([\n",
    "    [0.067502, 0.634745, 0.770678, 0.925945, 0.431622, 0.542899],\n",
    "    [0.400345, 0.617435, 0.564076, 0.028873, 0.730474, 0.787245],\n",
    "    [0.508267, 0.997521, 0.358960, 0.745010, 0.251294, 0.856409],\n",
    "    [0.969578, 0.930527, 0.346056, 0.836240, 0.228505, 0.712374],\n",
    "    [0.120703, 0.031424, 0.856331, 0.160061, 0.069200, 0.239120],\n",
    "    [0.441479, 0.750750, 0.472307, 0.601996, 0.790739, 0.013478],\n",
    "    [0.420520, 0.796570, 0.471162, 0.614847, 0.752107, 0.000000],\n",
    "    [0.497259, 0.809209, 0.414065, 0.676829, 0.781697, 0.009168],\n",
    "    [0.373715, 0.835038, 0.446694, 0.605948, 0.741489, 0.999999],\n",
    "    [0.375344, 0.810491, 0.463895, 0.588688, 0.741848, 0.000001],\n",
    "    [0.355653, 0.801633, 0.457118, 0.569002, 0.748664, 0.000001],\n",
    "    [0.384396, 0.812922, 0.458117, 0.582021, 0.732893, 0.001000]\n",
    "])\n",
    "new_y = np.array([0.03701472059292424, 0.21975396773107775, 0.018112125701738212,\n",
    "                  0.0034485098578360953, 0.16586065795194388, 2.5372438665513246,\n",
    "                  2.756700494633134, 2.229887072011708, 0.012566251593762408,\n",
    "                  2.8204962634535247, 2.720129145400815, 2.8596484501030517])\n",
    "\n",
    "\n",
    "X_init = np.vstack([X_init, new_X])\n",
    "y_init = np.append(y_init, new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C, WhiteKernel\n",
    "import numpy as np\n",
    "\n",
    "# --- Rebuild GP with ARD ---\n",
    "kernel = (\n",
    "    C(1.0, (1e-3, 1e3)) *\n",
    "    Matern(length_scale=np.ones(6), length_scale_bounds=(1e-3, 1e3), nu=2.5)\n",
    ") + WhiteKernel(noise_level=1e-4, noise_level_bounds=(1e-6, 1e-2))\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    normalize_y=True,\n",
    "    alpha=1e-6,                 # numerical jitter\n",
    "    n_restarts_optimizer=20,    # IMPORTANT\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gp.fit(X_init, y_init)\n",
    "y_best = y_init.max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "- Reduce perturbation further: perturbation = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def expected_improvement(X, gp, y_best, xi=0.001):\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    ei[sigma < 1e-12] = 0.0\n",
    "    return ei\n",
    "\n",
    "def final_polish_micro_perturbation(\n",
    "    gp,\n",
    "    best_point,\n",
    "    y_best,\n",
    "    n_candidates=500,\n",
    "    perturbation=0.005,  # slightly reduce perturbation\n",
    "    top_k=3\n",
    "):\n",
    "    d = len(best_point)\n",
    "\n",
    "    # Generate very small local perturbations\n",
    "    X = best_point + (np.random.rand(n_candidates, d) - 0.5) * 2 * perturbation\n",
    "    X = np.clip(X, 0, 1)\n",
    "\n",
    "    # Enforce known structure: dim6 ≈ 0\n",
    "    X[:, 5] = np.clip(X[:, 5], 0, 1e-3)\n",
    "\n",
    "    ei = expected_improvement(X, gp, y_best, xi=0.001)\n",
    "\n",
    "    idx = np.argsort(-ei)[:top_k]\n",
    "    return X[idx], ei[idx]\n",
    "\n",
    "# ---- USAGE ----\n",
    "# best_point = np.array([0.375344, 0.810491, 0.463895, 0.588688, 0.741848, 0.000001])\n",
    "# y_best = 2.8204962634535247\n",
    "# candidates, ei_vals = final_polish_micro_perturbation(gp, best_point, y_best)\n",
    "\n",
    "# print(\"Final polish candidates:\")\n",
    "# print(candidates)\n",
    "# print(\"EI values:\")\n",
    "# print(ei_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_point = np.array([0.384396, 0.812922, 0.458117, 0.582021, 0.732893, 0.001000])\n",
    "y_best = 2.8596484501030517\n",
    "\n",
    "candidates, ei_vals = final_polish_micro_perturbation(gp, best_point, y_best)\n",
    "\n",
    "print(\"Final polish candidates:\")\n",
    "print(candidates)\n",
    "print(\"EI values:\")\n",
    "print(ei_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Next point (6 dp):\", np.round(candidates[0], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- latst point is a near-neighbour of the current best\n",
    "- Best: [0.384396, 0.812922, 0.458117, 0.582021, 0.732893, 0.001000]\n",
    "- New : [0.386987, 0.810024, 0.458759, 0.583202, 0.727966, 0.001000]\n",
    "- 2.85626 vs 2.85965 (best)\n",
    "- This point confirms the peak is sharp and well-located; the slight performance drop is expected and indicates you are mapping the local curvature rather than missing a better region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
