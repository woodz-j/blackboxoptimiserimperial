{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -------------------------\n",
    "# Put your data here\n",
    "# -------------------------\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "# -------------------------\n",
    "# Transform / settings\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_init.shape[1])  # assume normalized [0,1] per dim\n",
    "dim = X_init.shape[1]\n",
    "y_best = y_init.max()\n",
    "\n",
    "# -------------------------\n",
    "# Fit GP surrogate\n",
    "# -------------------------\n",
    "kernel = Matern(length_scale=np.ones(dim),\n",
    "                length_scale_bounds=(1e-2, 1e2),\n",
    "                nu=2.5)\n",
    "# alpha = noise variance. If outputs are noisy, increase alpha (e.g. 1e-4 or tuned)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=5, random_state=0)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# -------------------------\n",
    "# Expected Improvement (EI)\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei  # note: maximize this\n",
    "\n",
    "# Negative EI for minimizers\n",
    "def neg_ei(x, gp, y_best, xi=0.01):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Acquisition optimization: many random starts + DE fallback\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40):\n",
    "    dim = bounds.shape[0]\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    # Random-start L-BFGS-B\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Try differential evolution as a global check (optional, slower)\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best),\n",
    "                                       bounds=bounds.tolist(),\n",
    "                                       maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # clamp to bounds and return\n",
    "    best_x = np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "    return best_x\n",
    "\n",
    "# -------------------------\n",
    "# If you need a small batch (greedy sequential EI)\n",
    "# -------------------------\n",
    "def propose_batch(gp, y_best, bounds, batch_size=3):\n",
    "    batch = []\n",
    "    gp_copy = gp\n",
    "    X_aug = X_init.copy()\n",
    "    y_aug = y_init.copy()\n",
    "    for i in range(batch_size):\n",
    "        x_next = propose_location(gp_copy, y_aug.max(), bounds)\n",
    "        # \"Fake\" evaluation: use GP predicted mean (Kriging believer)\n",
    "        y_fake = gp_copy.predict(x_next.reshape(1, -1))[0]\n",
    "        # Append to augmented set and refit GP (greedy sequential)\n",
    "        X_aug = np.vstack([X_aug, x_next])\n",
    "        y_aug = np.hstack([y_aug, y_fake])\n",
    "        gp_copy = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "        gp_copy.fit(X_aug, y_aug)\n",
    "        batch.append(x_next)\n",
    "    return np.array(batch)\n",
    "\n",
    "# -------------------------\n",
    "# Run proposal\n",
    "# -------------------------\n",
    "x_next = propose_location(gp, y_best, np.array(bounds))\n",
    "print(\"Suggested next point (continuous):\", x_next)\n",
    "\n",
    "# If some dims are categorical/encoded, round or map them here, e.g.:\n",
    "# x_next[cat_index] = int(np.round(x_next[cat_index] * (num_categories-1)))\n",
    "#\n",
    "# Example: If dim 6 encodes optimizer 0..3:\n",
    "# x_next[6] = int(np.round(x_next[6] * 3))\n",
    "\n",
    "# -------------------------\n",
    "# (Optional) propose a small batch\n",
    "# -------------------------\n",
    "batch = propose_batch(gp, y_best, np.array(bounds), batch_size=3)\n",
    "print(\"Suggested batch of 3 points (continuous):\\n\", batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Initial data ---\n",
    "#X_init = np.array([...])  # 30x6 array\n",
    "#y_init = np.array([...])  # 30 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "y_best = y_init.max()  # best performance so far\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization in scipy\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "bounds = [(0,1)]*6\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "for _ in range(20):  # multiple random starts\n",
    "    x0 = np.random.rand(6)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
