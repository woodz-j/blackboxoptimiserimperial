{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# Fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# Surrogate to maximise (negative for minimize)\n",
    "def surrogate_neg(x):\n",
    "    return -gp.predict(x.reshape(1, -1))[0]\n",
    "\n",
    "# Bounds for normalized inputs\n",
    "bounds = [(0,1), (0,1), (0,1), (0,1)]\n",
    "\n",
    "# Try multiple random starts to avoid local issues\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next point to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- New evaluated point ---\n",
    "x_new = np.array([0.973386, 0.889905, 0.981563, 0.242055])\n",
    "y_new = 2755.4496930419423\n",
    "\n",
    "# --- Add new data to dataset ---\n",
    "X_all = np.vstack([X_init, x_new])\n",
    "y_all = np.hstack([y_init, y_new])\n",
    "\n",
    "# --- Refit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Generate candidate next points around current best ---\n",
    "best_x = x_new\n",
    "sigma = 0.02  # tweak size for local exploration\n",
    "num_candidates = 5\n",
    "\n",
    "x_next_candidates = best_x + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "# Ensure all points are within [0,1]\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"Candidate next points to evaluate:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The new point still produced a very high yield, confirming that:\n",
    "You’re indeed near the global optimum.\n",
    "The response surface around the best point is smooth and relatively flat, so small parameter variations still yield high outputs.\n",
    "The optimum likely lies somewhere between those two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "✅ Adding both new high-yield points\n",
    "✅ Re-fitting the Gaussian Process with improved stability\n",
    "✅ Using a UCB-style acquisition for balanced exploration/exploitation\n",
    "✅ Local refinement with smaller perturbations (sigma = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- Add the two new data points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # best from previous run\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817]   # new high-yield point\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                # smaller noise term for precision\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5     # more robust kernel fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def surrogate_neg_ucb(x, kappa=2.0):\n",
    "    mean, std = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mean + kappa * std)\n",
    "\n",
    "# --- Search bounds for normalized inputs ---\n",
    "bounds = [(0, 1), (0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "# --- Optimize acquisition function for next sampling point ---\n",
    "best_x, best_val = None, float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "\n",
    "print(\"Suggested next point to evaluate:\", x_next)\n",
    "\n",
    "# --- Optionally: generate a few local perturbations for fine exploration ---\n",
    "sigma = 0.01\n",
    "num_candidates = 5\n",
    "x_next_candidates = x_next + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"\\nLocal candidate points for fine-tuning:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Suggested next point to evaluate:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New best: [0.999999, 0.999999, 0.999999, 0.024637]\n",
    "# 4440.50, which is a big jump over the previous best (~2755).\n",
    "# Implication 1: The optimum appears to lie at or extremely near the upper boundary for the first three variables (≈1.0).\n",
    "# Implication 2: The fourth variable is near zero (≈0.0246). Earlier high points had the fourth at ~0.24–0.30;\n",
    "# the new much better value suggests the peak may be at an extreme combination: first three maximized, fourth minimized.\n",
    "# Implication 3: Because the best is on (or very near) the boundary, we must be careful:\n",
    "# local symmetric perturbations may be misleading since you can’t go past 1.0.\n",
    "# The function may be unimodal but with its maximum on the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Because the optimum appears at extremes\n",
    "be cautious interpreting the GP far from observed data but your new top point strongly suggests a boundary optimum.\n",
    "The single most informative next experiment is the 1D sweep on the 4th variable while holding the first three at 1.0.\n",
    "That will tell you whether to push the fourth to exactly zero, or to some small positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # more robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "bounds = [(0,1),(0,1),(0,1),(0,1)]\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 1.0 ---\n",
    "fourth_grid = np.array([0.0, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 1.0) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([1.0, 1.0, 1.0, 0.0]),\n",
    "    np.array([0.995, 0.995, 0.995, 0.01]),\n",
    "    np.array([1.0, 1.0, 1.0, 0.05]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0, 1))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0, 1\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# --- TIGHTENED BOUNDS to avoid 0.0 or 1.0 ---\n",
    "bounds = [(0.02, 0.98)] * 4\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 0.98 (not 1.0 anymore) ---\n",
    "fourth_grid = np.array([0.02, 0.03, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 0.98) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([0.98, 0.98, 0.98, 0.02]),\n",
    "    np.array([0.97, 0.97, 0.97, 0.05]),\n",
    "    np.array([0.98, 0.98, 0.98, 0.1]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0.02, 0.98))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0.02, 0.98\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
