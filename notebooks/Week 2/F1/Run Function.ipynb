{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Update with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- 1. Initial data ---\n",
    "X_init = np.array([\n",
    "    [0.31940389, 0.76295937],\n",
    "    [0.57432921, 0.8798981],\n",
    "    [0.73102363, 0.73299988],\n",
    "    [0.84035342, 0.26473161],\n",
    "    [0.65011406, 0.68152635],\n",
    "    [0.41043714, 0.1475543],\n",
    "    [0.31269116, 0.07872278],\n",
    "    [0.68341817, 0.86105746],\n",
    "    [0.08250725, 0.40348751],\n",
    "    [0.88388983, 0.58225397]\n",
    "])\n",
    "\n",
    "y_init = np.array([\n",
    "    1.32267704e-079,  1.03307824e-046,  7.71087511e-016,\n",
    "    3.34177101e-124, -3.60606264e-003, -2.15924904e-054,\n",
    "    -2.08909327e-091,  2.53500115e-040,  3.60677119e-081,\n",
    "    6.22985647e-048\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new observation\n",
    "X_new = np.array([[0.080808, 0.404040]])\n",
    "y_new = np.array([5.34214011784672e-82])\n",
    "\n",
    "# Combine with previous data\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])\n",
    "\n",
    "X_init = X_all\n",
    "y_init = y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_init)\n",
    "print(X_init.shape)   # Useful if it’s an array\n",
    "print(type(X_init)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_init)\n",
    "print(y_init.shape)   # Useful if it’s an array\n",
    "print(type(y_init)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Week 1 UCB method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Log-transform to handle sparse/near-zero outputs\n",
    "#y_trans = np.log(np.abs(y_init) + 1e-8)\n",
    "y_trans = y_init.copy()  # Use raw outputs\n",
    "\n",
    "\n",
    "# --- 2. Fit Gaussian Process ---\n",
    "#kernel = Matern(nu=2.5)\n",
    "#gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "\n",
    "kernel = Matern(length_scale=0.1, nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "\n",
    "gp.fit(X_init, y_trans)\n",
    "\n",
    "# --- 3. Define UCB acquisition function ---\n",
    "def acquisition_ucb(X, gp, kappa=2.0):\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    return mu + kappa * sigma\n",
    "\n",
    "# --- 4. Generate candidate points on a 2D grid ---\n",
    "grid_size = 100\n",
    "x1 = np.linspace(0, 1, grid_size)\n",
    "x2 = np.linspace(0, 1, grid_size)\n",
    "X_candidates = np.array([[i, j] for i in x1 for j in x2])\n",
    "\n",
    "# --- 5. Evaluate acquisition function ---\n",
    "acq_values = acquisition_ucb(X_candidates, gp, kappa=2.5)\n",
    "\n",
    "# --- 6. Select next point ---\n",
    "next_point = X_candidates[np.argmax(acq_values)]\n",
    "print(\"Next point to query:\", next_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stabilize and preserve sign (for small negative readings)\n",
    "y_trans = np.sign(y_all) * np.log10(np.abs(y_all) + 1e-20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Matern(length_scale=0.15, nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_all, y_trans)\n",
    "\n",
    "###\n",
    "#Note: slightly increase length_scale — your previous grid suggests spatial correlation extends across ~0.1–0.2 units.\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Choose a smarter acquisition strategy\n",
    "Bootstrapping is a resampling method where you generate multiple samples with replacement from your original data. You then calculate the statistic (mean, median, correlation, etc.) on each sample to understand the variability and uncertainty of that statistic.\n",
    "\n",
    "**Scenario**\n",
    "UCB (mu + κσ) is good for exploration, but since I have mostly near-zero outputs, we may want to mix in exploration and exploitation adaptively.\n",
    "\n",
    "Try using Expected Improvement (EI) instead of UCB.\n",
    "It’s more focused on discovering true peaks when most readings are near noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def acquisition_ei(X, gp, y_best, xi=0.01):\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    sigma = sigma.reshape(-1, 1)\n",
    "    mu = mu.reshape(-1, 1)\n",
    "\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / (sigma + 1e-9)\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D grid of candidates\n",
    "grid_size = 100\n",
    "x1 = np.linspace(0, 1, grid_size)\n",
    "x2 = np.linspace(0, 1, grid_size)\n",
    "X_candidates = np.array([[i, j] for i in x1 for j in x2])\n",
    "\n",
    "# Best observed value\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# Compute acquisition values\n",
    "acq_values = acquisition_ei(X_candidates, gp, y_best, xi=0.02)\n",
    "\n",
    "# Select next point\n",
    "next_point = X_candidates[np.argmax(acq_values)]\n",
    "print(\"Next point to query:\", next_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
