{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if itâ€™s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if itâ€™s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "#X_init = ... # 20x5 array\n",
    "#y_init = ... # 20 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Define Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0,1)]*5  # 5 ingredients\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "# Multiple random starts to avoid local maxima\n",
    "for _ in range(20):\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Step 0: Load and update data ---\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# Add the most recent data point\n",
    "x_new = np.array([[0.861642, 0.308166, 0.510818, 0.325615, 0.845503]])\n",
    "y_new = np.array([-1.7791349472320002])\n",
    "\n",
    "# Combine with existing data\n",
    "X_init = np.vstack([datain, x_new])\n",
    "y_init = np.hstack([dataout, y_new])\n",
    "\n",
    "print(X_init)\n",
    "print(y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init   # since we want to make score close to zero (maximise negative of total)\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)\n",
    "\n",
    "# --- Step 3: Define acquisition functions ---\n",
    "\n",
    "# Expected Improvement (EI)\n",
    "def expected_improvement(x, gp, y_best, xi=0.05):  # adjust xi for exploration/exploitation balance\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # we minimize in scipy\n",
    "\n",
    "# --- (Optional) UCB version: uncomment to use ---\n",
    "# def ucb(x, gp, kappa=2.0):\n",
    "#     x = np.array(x).reshape(1, -1)\n",
    "#     mu, sigma = gp.predict(x, return_std=True)\n",
    "#     return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0, 1)] * 5\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "\n",
    "for _ in range(40):  # more restarts to reduce local optima risk\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    # --- For UCB, replace expected_improvement(...) with ucb(...)\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Summary of changes:\n",
    "âœ… Added the two new data points (x_new1, x_new2)\n",
    "âœ… Reduced xi from 0.02 to 0.01 â†’ focuses on exploitation\n",
    "âœ… Increased random restarts to 50 for robustness\n",
    "ðŸ’¬ Kept UCB commented out (can easily be enabled later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Step 0: Load and update data ---\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# Add previously tested new points\n",
    "x_new1 = np.array([[0.861642, 0.308166, 0.510818, 0.325615, 0.845503]])\n",
    "y_new1 = np.array([-1.7791349472320002])\n",
    "\n",
    "x_new2 = np.array([[0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269]])\n",
    "y_new2 = np.array([-1.3401340011620242])\n",
    "\n",
    "# Combine with existing data\n",
    "X_init = np.vstack([datain, x_new1, x_new2])\n",
    "y_init = np.hstack([dataout, y_new1, y_new2])\n",
    "\n",
    "# --- Step 1: Transform outputs for maximization ---\n",
    "y_transformed = -y_init\n",
    "y_best = y_transformed.max()\n",
    "\n",
    "# --- Step 2: Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_transformed)\n",
    "\n",
    "# --- Step 3: Define acquisition functions ---\n",
    "\n",
    "# Expected Improvement (EI)\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):  # reduced xi for more exploitation\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize because scipy.optimize minimizes by default\n",
    "\n",
    "# --- (Optional) UCB version: uncomment to use ---\n",
    "# def ucb(x, gp, kappa=2.0):\n",
    "#     x = np.array(x).reshape(1, -1)\n",
    "#     mu, sigma = gp.predict(x, return_std=True)\n",
    "#     return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "# --- Step 4: Optimize acquisition function ---\n",
    "bounds = [(0, 1)] * 5\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "\n",
    "for _ in range(50):  # increased restarts for better global search\n",
    "    x0 = np.random.rand(5)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    # --- For UCB, replace expected_improvement(...) with ucb(...)\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next recipe to try:\", x_next)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Next recipe to try:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The new point [0.304171, 0.964306, 0.527203, 0.006037, 0.376271] gave -1.8371,\n",
    "which is worse than the previous new samples and far worse than the current best (-0.7143).\n",
    "That tells us this region of input space is likely a poor area â€” we should record it and let the GP learn low values there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Add the new point to the dataset and refit the GP.\n",
    "Use Expected Improvement (EI) as the acquisition function but reduce xi to favor exploitation (I recommend xi = 0.005â€“0.01).\n",
    "Compute one exploratory candidate using UCB with a larger kappa like 3.0) so you can occasionally sample high-uncertainty regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271])   # most recent\n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3])\n",
    "\n",
    "# transform for maximization\n",
    "y_trans = -y\n",
    "y_best = y_trans.max()\n",
    "\n",
    "# Fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# Acquisition: Expected Improvement\n",
    "def expected_improvement(x, gp, y_best, xi=0.005):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma <= 1e-12:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # minimize\n",
    "\n",
    "# Optional: Upper Confidence Bound (for exploration)\n",
    "def ucb(x, gp, kappa=3.0):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative since we minimize\n",
    "\n",
    "bounds = [(0.0, 1.0)] * X.shape[1]\n",
    "\n",
    "# Helper optimizer that runs many restarts and also starts near a given seed\n",
    "def optimize_acq(acq_func, gp, y_best, n_restarts=40, local_seeds=None):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "    # global random restarts\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(X.shape[1])\n",
    "        res = minimize(lambda xx: acq_func(xx, gp, y_best),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    # local starts near seeds (if provided)\n",
    "    if local_seeds is not None:\n",
    "        for seed in local_seeds:\n",
    "            for _ in range(8):  # a few noisy local starts\n",
    "                x0 = seed + 0.05 * np.random.randn(X.shape[1])\n",
    "                x0 = np.clip(x0, 0.0, 1.0)\n",
    "                res = minimize(lambda xx: acq_func(xx, gp, y_best),\n",
    "                               x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "                if res.success and res.fun < best_val:\n",
    "                    best_val = res.fun\n",
    "                    best_x = res.x\n",
    "    return best_x, best_val\n",
    "\n",
    "# Identify current best input (from the dataset)\n",
    "idx_best = np.argmax(y_trans)  # index of best transformed value\n",
    "x_best = X[idx_best]\n",
    "\n",
    "# Exploitative candidate: EI with local seeds near current best\n",
    "x_next_exploit, val_e = optimize_acq(expected_improvement, gp, y_best,\n",
    "                                     n_restarts=40, local_seeds=[x_best])\n",
    "\n",
    "# Exploratory candidate: high-kappa UCB (optional)\n",
    "x_next_explore, val_u = optimize_acq(lambda xx,gp,yb: ucb(xx,gp,kappa=3.0), gp, y_best,\n",
    "                                     n_restarts=40, local_seeds=None)\n",
    "\n",
    "print(\"Current best (transformed):\", y_best, \"at X =\", x_best)\n",
    "print(\"Exploitative next (EI, xi=0.005):\", x_next_exploit)\n",
    "print(\"Exploratory next (UCB, kappa=3.0):\", x_next_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Going with Exploitative next (EI, xi=0.005): [0.13368735 0.61046861 0.48527119 0.33635839 0.75270271]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_exploit, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "- New input: [0.133687, 0.610469, 0.485271, 0.336358, 0.752703] â†’ output -1.7633.\n",
    "- That neighborhood already contains several poor values, so the new -1.76 is consistent with (and reinforces) that assessment.\n",
    "- EI will be pushed toward regions with higher predicted means (the good basins) once the GP is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "- The new sample confirmed that part of the space is bad â€” donâ€™t waste more samples there now.\n",
    "- Focus on small, local steps around the current best to climb the nearby basin,\n",
    "- but keep one periodic, deliberate exploration to escape local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load original data ---\n",
    "X_init = np.load('initial_inputs.npy')         # shape (20,5)\n",
    "y_init = np.load('initial_outputs.npy')        # shape (20,)\n",
    "\n",
    "# --- Append the previously tested new points (including the most recent) ---\n",
    "x_new1 = np.array([0.861642, 0.308166, 0.510818, 0.325615, 0.845503])\n",
    "y_new1 = -1.7791349472320002\n",
    "\n",
    "x_new2 = np.array([0.52685018, 0.5778152, 0.74790401, 0.62958138, 0.84857269])\n",
    "y_new2 = -1.3401340011620242\n",
    "\n",
    "x_new3 = np.array([0.304171, 0.964306, 0.527203, 0.006037, 0.376271]) \n",
    "y_new3 = -1.8370828066160314\n",
    "\n",
    "x_new4 = np.array([0.133687, 0.610469, 0.485271, 0.336358, 0.752703])   # most recent\n",
    "y_new4 = -1.7632847898105413\n",
    "\n",
    "X = np.vstack([X_init, x_new1, x_new2, x_new3, x_new4])\n",
    "y = np.hstack([y_init, y_new1, y_new2, y_new3, y_new4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Computes one next point using Expected Improvement (EI) (exploit),\n",
    "Computes one next point using Upper Confidence Bound (UCB) (explore).\n",
    "- We are going to use the exploit version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Transform outputs for maximisation ===\n",
    "y_trans = -y        # since we want to bring score toward 0\n",
    "y_best = np.max(y_trans)\n",
    "\n",
    "# === Fit Gaussian Process ===\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X, y_trans)\n",
    "\n",
    "# === Acquisition Functions ===\n",
    "def expected_improvement(x, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0:\n",
    "        return 0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization in scipy\n",
    "\n",
    "def ucb(x, kappa=2.5):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)  # negative for minimization\n",
    "\n",
    "# === Optimize acquisition function ===\n",
    "bounds = [(0,1)] * 5\n",
    "\n",
    "def optimize(acq):\n",
    "    best_x = None\n",
    "    best_val = float(\"inf\")\n",
    "    for _ in range(40):  # multiple random restarts\n",
    "        x0 = np.random.rand(5)\n",
    "        res = minimize(acq, x0=x0, bounds=bounds, method=\"L-BFGS-B\")\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# === Next point to evaluate ===\n",
    "x_next_EI = optimize(expected_improvement)\n",
    "# x_next_UCB = optimize(lambda x: ucb(x))   # â† Uncomment to use exploration candidate\n",
    "\n",
    "print(\"Next exploitative EI point:\", x_next_EI)\n",
    "# print(\"Next exploratory UCB point:\", x_next_UCB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_EI, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
