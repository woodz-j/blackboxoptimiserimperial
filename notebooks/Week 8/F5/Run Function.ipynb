{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# Fit GP\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# Surrogate to maximise (negative for minimize)\n",
    "def surrogate_neg(x):\n",
    "    return -gp.predict(x.reshape(1, -1))[0]\n",
    "\n",
    "# Bounds for normalized inputs\n",
    "bounds = [(0,1), (0,1), (0,1), (0,1)]\n",
    "\n",
    "# Try multiple random starts to avoid local issues\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next point to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- New evaluated point ---\n",
    "x_new = np.array([0.973386, 0.889905, 0.981563, 0.242055])\n",
    "y_new = 2755.4496930419423\n",
    "\n",
    "# --- Add new data to dataset ---\n",
    "X_all = np.vstack([X_init, x_new])\n",
    "y_all = np.hstack([y_init, y_new])\n",
    "\n",
    "# --- Refit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Generate candidate next points around current best ---\n",
    "best_x = x_new\n",
    "sigma = 0.02  # tweak size for local exploration\n",
    "num_candidates = 5\n",
    "\n",
    "x_next_candidates = best_x + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "# Ensure all points are within [0,1]\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"Candidate next points to evaluate:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The new point still produced a very high yield, confirming that:\n",
    "You’re indeed near the global optimum.\n",
    "The response surface around the best point is smooth and relatively flat, so small parameter variations still yield high outputs.\n",
    "The optimum likely lies somewhere between those two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "✅ Adding both new high-yield points\n",
    "✅ Re-fitting the Gaussian Process with improved stability\n",
    "✅ Using a UCB-style acquisition for balanced exploration/exploitation\n",
    "✅ Local refinement with smaller perturbations (sigma = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- Existing data ---\n",
    "X_init = datain           # shape (n_samples, 4)\n",
    "y_init = dataout          # shape (n_samples,)\n",
    "\n",
    "# --- Add the two new data points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # best from previous run\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817]   # new high-yield point\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                # smaller noise term for precision\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5     # more robust kernel fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def surrogate_neg_ucb(x, kappa=2.0):\n",
    "    mean, std = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mean + kappa * std)\n",
    "\n",
    "# --- Search bounds for normalized inputs ---\n",
    "bounds = [(0, 1), (0, 1), (0, 1), (0, 1)]\n",
    "\n",
    "# --- Optimize acquisition function for next sampling point ---\n",
    "best_x, best_val = None, float('inf')\n",
    "for _ in range(10):\n",
    "    x0 = np.random.rand(4)\n",
    "    res = minimize(surrogate_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "\n",
    "print(\"Suggested next point to evaluate:\", x_next)\n",
    "\n",
    "# --- Optionally: generate a few local perturbations for fine exploration ---\n",
    "sigma = 0.01\n",
    "num_candidates = 5\n",
    "x_next_candidates = x_next + np.random.normal(0, sigma, size=(num_candidates, 4))\n",
    "x_next_candidates = np.clip(x_next_candidates, 0, 1)\n",
    "\n",
    "print(\"\\nLocal candidate points for fine-tuning:\")\n",
    "print(x_next_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Suggested next point to evaluate:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New best: [0.999999, 0.999999, 0.999999, 0.024637]\n",
    "# 4440.50, which is a big jump over the previous best (~2755).\n",
    "# Implication 1: The optimum appears to lie at or extremely near the upper boundary for the first three variables (≈1.0).\n",
    "# Implication 2: The fourth variable is near zero (≈0.0246). Earlier high points had the fourth at ~0.24–0.30;\n",
    "# the new much better value suggests the peak may be at an extreme combination: first three maximized, fourth minimized.\n",
    "# Implication 3: Because the best is on (or very near) the boundary, we must be careful:\n",
    "# local symmetric perturbations may be misleading since you can’t go past 1.0.\n",
    "# The function may be unimodal but with its maximum on the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Because the optimum appears at extremes\n",
    "be cautious interpreting the GP far from observed data but your new top point strongly suggests a boundary optimum.\n",
    "The single most informative next experiment is the 1D sweep on the 4th variable while holding the first three at 1.0.\n",
    "That will tell you whether to push the fourth to exactly zero, or to some small positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # more robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "bounds = [(0,1),(0,1),(0,1),(0,1)]\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 1.0 ---\n",
    "fourth_grid = np.array([0.0, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    np.ones_like(fourth_grid),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 1.0) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([1.0, 1.0, 1.0, 0.0]),\n",
    "    np.array([0.995, 0.995, 0.995, 0.01]),\n",
    "    np.array([1.0, 1.0, 1.0, 0.05]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0, 1))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0, 1\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637]   # current best\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])\n",
    "\n",
    "# --- Fit updated Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,                 # low noise for precision near smooth peak\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8      # robust hyperparameter fitting\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Define acquisition function (UCB variant) ---\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# --- TIGHTENED BOUNDS to avoid 0.0 or 1.0 ---\n",
    "bounds = [(0.02, 0.98)] * 4\n",
    "\n",
    "# --- 1) 1D sweep over the 4th variable with first 3 fixed at 0.98 (not 1.0 anymore) ---\n",
    "fourth_grid = np.array([0.02, 0.03, 0.05, 0.1, 0.2, 0.3])\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    fourth_grid\n",
    "])\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep (first 3 = 0.98) — predicted mean yields:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# --- 2) Acquisition optimization with boundary-aware seeds ---\n",
    "best_x, best_val = None, float('inf')\n",
    "seeds = [\n",
    "    new_points[-1],                          # current best\n",
    "    np.array([0.98, 0.98, 0.98, 0.02]),\n",
    "    np.array([0.97, 0.97, 0.97, 0.05]),\n",
    "    np.array([0.98, 0.98, 0.98, 0.1]),\n",
    "]\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0.02, 0.98))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B',\n",
    "                   options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "\n",
    "# --- 3) Local fine candidates around best_x ---\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)), 0.02, 0.98\n",
    ")\n",
    "\n",
    "# Combine with top sweep points for next tests\n",
    "candidates = np.vstack([top_sweep_points, local_candidates, best_x.reshape(1, -1)])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "- New point: [0.98, 0.98, 0.98, 0.02] → 3669.14.\n",
    "- Compare with prior highs:\n",
    "[0.9639, 0.8684, 0.9870, 0.2958] → 2574\n",
    "[0.9734, 0.8899, 0.9816, 0.2421] → 2755\n",
    "[0.999999,0.999999,0.999999,0.024637] → 4440.50 (best so far)\n",
    "- the model appears monotonic (or strongly increasing) in x1–x3 toward their upper edge, and prefers a small positive x4 near ~0.02–0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02] \n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume datain / dataout already loaded as before\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# fit GP (same settings)\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=8)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# bounds (tightened)\n",
    "bounds = [(0.02, 0.98)] * 4\n",
    "\n",
    "# 1D sweep for x4 with first three = 0.98\n",
    "fourth_grid = np.array([0.02, 0.025, 0.03, 0.04, 0.06])\n",
    "sweep_points = np.column_stack([np.full_like(fourth_grid, 0.98),\n",
    "                                np.full_like(fourth_grid, 0.98),\n",
    "                                np.full_like(fourth_grid, 0.98),\n",
    "                                fourth_grid])\n",
    "sweep_means = gp.predict(sweep_points)\n",
    "for p, m in zip(sweep_points, sweep_means):\n",
    "    print(p, \"→ predicted mean:\", m)\n",
    "\n",
    "# choose best sweep x4 (predicted) and create sensitivity tests for x1-3\n",
    "best_idx = np.argmax(sweep_means)\n",
    "best_x4 = fourth_grid[best_idx]\n",
    "\n",
    "first_three_tests = np.array([[v, v, v, best_x4] for v in [0.95, 0.97, 0.98]])\n",
    "print(\"\\nFirst-3 sensitivity candidates (x4 fixed):\")\n",
    "for p in first_three_tests:\n",
    "    print(p, \"→\", gp.predict(p.reshape(1,-1))[0])\n",
    "\n",
    "# local perturbations around [0.98,0.98,0.98,best_x4]\n",
    "sigma = 0.005\n",
    "local_cands = np.clip(np.tile([0.98,0.98,0.98,best_x4], (6,1)) + np.random.normal(0, sigma, (6,4)), 0.02, 0.98)\n",
    "print(\"\\nLocal perturbation candidates:\")\n",
    "for p in local_cands:\n",
    "    print(p, \"→\", gp.predict(p.reshape(1,-1))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assumes gp is already fitted and new_points etc. are in place ---\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1) Reuse the previously computed best_x if you have it; otherwise run acquisition optimization quickly:\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# quick acquisition optimization to get a candidate (optional)\n",
    "bounds = [(0.02,0.98)]*4\n",
    "best_x = None\n",
    "best_val = float('inf')\n",
    "seeds = [new_points[-1], np.array([0.98,0.98,0.98,0.02]), np.array([0.97,0.97,0.97,0.05])]\n",
    "for _ in range(6):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, 0.02, 0.98))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds, method='L-BFGS-B', options={'maxiter':100})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# 2) Build candidate list: sweep on x4 (x1-3 = 0.98), the acquisition best_x, and a few local perturbs\n",
    "fourth_grid = np.array([0.02, 0.025, 0.03, 0.04, 0.06])\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    np.full_like(fourth_grid, 0.98),\n",
    "    fourth_grid\n",
    "])\n",
    "\n",
    "# local perturbations around best_x\n",
    "np.random.seed(0)\n",
    "local = np.clip(best_x + np.random.normal(0, 0.005, size=(5,4)), 0.02, 0.98)\n",
    "\n",
    "# combine and deduplicate\n",
    "candidates = np.vstack([sweep_points, local, best_x.reshape(1,-1)])\n",
    "# optional: remove duplicates (numerically)\n",
    "unique_candidates = np.unique(np.round(candidates, 6), axis=0)\n",
    "\n",
    "# 3) Evaluate GP predictive mean and pick single best\n",
    "means = gp.predict(unique_candidates)\n",
    "best_idx = np.argmax(means)\n",
    "single_best = unique_candidates[best_idx]\n",
    "\n",
    "print(\"Single best candidate (highest predicted mean):\", single_best)\n",
    "print(\"Predicted mean yield:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(single_best, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "- [0.980000, 0.980000, 0.980000, 0.060000] Essentially identical to previous point (~0.0001 higher)\n",
    "- [0.999999,0.999999,0.999999,0.024637] 4440 Peak observed so far, very high first three inputs, small x4 (~0.0246)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "- By keeping bounds artificially tight I may be preventing access to higher yields.\n",
    "- Relaxing the bounds toward 1.0 will very likely increase yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- LOAD EXISTING DATA (your above snippet) ---\n",
    "\n",
    "# --- Fit GP (same settings you've been using) ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=8)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Build candidate set that probes toward the boundary safely ---\n",
    "# grid for x1-x3 near boundary (you can change values)\n",
    "x_levels = np.array([0.98, 0.985, 0.99, 0.995])  # include 1.0 only if allowed\n",
    "# keep x4 near the small region we've seen best\n",
    "x4_levels = np.array([0.02, 0.025, 0.03, 0.04])\n",
    "\n",
    "candidates = []\n",
    "for a in x_levels:\n",
    "    for b in x4_levels:\n",
    "        candidates.append([a, a, a, b])\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Optionally, remove candidates equal to points you've already tested (to avoid duplication)\n",
    "# (simple numeric comparison, adjust tolerance if necessary)\n",
    "def not_duplicate(c, X_existing, tol=1e-6):\n",
    "    return not np.any(np.all(np.abs(X_existing - c) <= tol, axis=1))\n",
    "\n",
    "filtered = np.array([c for c in candidates if not_duplicate(c, X_all)])\n",
    "if filtered.shape[0] == 0:\n",
    "    filtered = candidates  # fallback if everything was present\n",
    "\n",
    "# --- Predictive means and uncertainties ---\n",
    "means, stds = gp.predict(filtered, return_std=True)\n",
    "\n",
    "# --- Rank by predicted mean (descending) ---\n",
    "order = np.argsort(means)[::-1]\n",
    "ranked = filtered[order]\n",
    "ranked_means = means[order]\n",
    "ranked_stds = stds[order]\n",
    "\n",
    "# Print top-k candidates\n",
    "k = min(6, len(ranked))\n",
    "print(\"Top candidates to probe toward boundary (ranked by GP mean):\")\n",
    "for i in range(k):\n",
    "    print(f\"{i+1}: {ranked[i]}  predicted_mean={ranked_means[i]:.2f}, std={ranked_stds[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "- New point: [0.995, 0.995, 0.995, 0.03] → 4236.36.\n",
    "- This sits between the 0.98-triple results (~3669) and the unconstrained 1.0-triple best (4440.50).\n",
    "- Consistent pattern: increasing x1–x3 toward 1.0 yields large, roughly monotonic gains. x4 around 0.02–0.03 remains in the sweet-spot (and shows a fairly flat plateau).\n",
    "- Takeaway: you’re seeing strong, consistent improvement as you step from 0.98 → 0.995 → 1.0 for x1–x3. The unconstrained corner still looks best, but 0.995 captured most of the gain already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# --- assume datain, dataout already loaded ---\n",
    "# append latest result above\n",
    "\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-8, normalize_y=True, n_restarts_optimizer=6)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# build candidate set probing to boundary (adjust including 1.0 only if allowed)\n",
    "x_levels = np.array([0.995, 0.997, 0.999])  # remove 1.0 if disallowed\n",
    "x4_levels = np.array([0.02, 0.025, 0.03])\n",
    "\n",
    "candidates = np.array([[a, a, a, b] for a in x_levels for b in x4_levels])\n",
    "\n",
    "# remove duplicates already tested\n",
    "def not_duplicate(c, X_exist, tol=1e-8):\n",
    "    return not np.any(np.all(np.abs(X_exist - c) <= tol, axis=1))\n",
    "\n",
    "cand_filtered = np.array([c for c in candidates if not_duplicate(c, X_all)])\n",
    "if cand_filtered.size == 0:\n",
    "    cand_filtered = candidates  # fallback\n",
    "\n",
    "# predict means and pick highest-mean candidate\n",
    "means = gp.predict(cand_filtered)\n",
    "best_idx = np.argmax(means)\n",
    "single_best = cand_filtered[best_idx]\n",
    "print(\"Single best exploitation pick:\", single_best, \"predicted mean:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "- [0.999, 0.999, 0.999, 0.02] → 4399.07 is very close to the best observed 4440.50 at the near-exact corner.\n",
    "- The data show a consistent, roughly monotonic rise in yield as x1–x3 move from 0.98 → 0.995 → 0.999 → 1.0, with x4 small (~0.02–0.03) giving the best results.\n",
    "- Diminishing returns are apparent: the step from 0.995 → 0.999 produced a substantial gain, but the last step to 1.0 yields a relatively small expected improvement (~41 units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "# --- Existing base data ---\n",
    "X_init = datain.copy()       # shape (n_samples, 4)\n",
    "y_init = dataout.copy()      # shape (n_samples,)\n",
    "\n",
    "# --- Add all known evaluated high-yield points ---\n",
    "new_points = np.array([\n",
    "    [0.973386, 0.889905, 0.981563, 0.242055],  # first improvement\n",
    "    [0.963910, 0.868445, 0.987031, 0.295817],  # second\n",
    "    [0.999999, 0.999999, 0.999999, 0.024637],  # current best\n",
    "    [0.98, 0.98, 0.98, 0.02],\n",
    "    [0.980000, 0.980000, 0.980000, 0.060000],\n",
    "    [0.995000, 0.995000, 0.995000, 0.030000],\n",
    "    [0.999000, 0.999000, 0.999000, 0.020000]\n",
    "])\n",
    "new_outputs = np.array([\n",
    "    2755.4496930419423,\n",
    "    2574.150115501027,\n",
    "    4440.500188145975,\n",
    "    3669.139092257369,\n",
    "    3669.260114942143,\n",
    "    4236.357853784177,\n",
    "    4399.068182663082\n",
    "])\n",
    "\n",
    "# --- Combine all data ---\n",
    "X_all = np.vstack([X_init, new_points])\n",
    "y_all = np.hstack([y_init, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# fit GP\n",
    "gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-8, normalize_y=True, n_restarts_optimizer=6)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# candidate set (include exact corner only if allowed)\n",
    "candidates = np.array([\n",
    "    [0.9995, 0.9995, 0.9995, 0.025],\n",
    "    [0.999, 0.999, 0.999, 0.025],\n",
    "    [0.995, 0.995, 0.995, 0.025],\n",
    "    [0.98, 0.98, 0.98, 0.03]\n",
    "])\n",
    "# filter duplicates\n",
    "candidates = np.array([c for c in candidates if not np.any(np.all(np.isclose(X_all, c, atol=1e-8), axis=1))])\n",
    "\n",
    "means = gp.predict(candidates)\n",
    "best_idx = np.argmax(means)\n",
    "print(\"Single best candidate:\", candidates[best_idx], \"predicted mean:\", means[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ===============================\n",
    "# Gaussian Process Model\n",
    "# ===============================\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-8,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# ===============================\n",
    "# Acquisition Function (UCB)\n",
    "# ===============================\n",
    "def acq_neg_ucb(x, kappa=2.0):\n",
    "    x = np.asarray(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    return -(mu + kappa * sigma)\n",
    "\n",
    "# ===============================\n",
    "# Bounds (avoid hitting exact 0 or 1)\n",
    "# ===============================\n",
    "eps = 0.001\n",
    "bounds = [(eps, 1 - eps)] * 4\n",
    "\n",
    "# ===============================\n",
    "# 1D Sweep — keep first 3 ≈ high region\n",
    "# ===============================\n",
    "fourth_grid = np.array([0.002, 0.005, 0.01, 0.02, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2])\n",
    "\n",
    "sweep_points = np.column_stack([\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    np.full_like(fourth_grid, 1 - eps),\n",
    "    fourth_grid\n",
    "])\n",
    "\n",
    "means = gp.predict(sweep_points)\n",
    "print(\"1D sweep predictions for varying 4th variable:\")\n",
    "for x, m in zip(sweep_points, means):\n",
    "    print(x, \"→\", m)\n",
    "\n",
    "top_idx = np.argsort(means)[-3:][::-1]\n",
    "top_sweep_points = sweep_points[top_idx]\n",
    "\n",
    "# ===============================\n",
    "# Acquisition Optimization\n",
    "# ===============================\n",
    "best_x, best_val = None, float('inf')\n",
    "\n",
    "seeds = [\n",
    "    new_points[-1].clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, eps]),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.02]).clip(eps, 1-eps),\n",
    "    np.array([1-eps, 1-eps, 1-eps, 0.05]).clip(eps, 1-eps),\n",
    "]\n",
    "\n",
    "# jittered seeds near current high-yield region\n",
    "for _ in range(8):\n",
    "    jitter = np.random.normal(0, 0.01, 4)\n",
    "    seeds.append(np.clip(new_points[-1] + jitter, eps, 1 - eps))\n",
    "\n",
    "for x0 in seeds:\n",
    "    res = minimize(acq_neg_ucb, x0=x0, bounds=bounds,\n",
    "                   method='L-BFGS-B', options={'maxiter': 200})\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"\\nAcquisition-opt suggested next point:\", best_x, \"acq value:\", -best_val)\n",
    "print(\"Next point (6 dp):\", np.round(best_x, 6))\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Local candidate set around best_x\n",
    "# ===============================\n",
    "sigma = 0.005\n",
    "num_candidates = 6\n",
    "\n",
    "local_candidates = np.clip(\n",
    "    best_x + np.random.normal(0, sigma, size=(num_candidates, 4)),\n",
    "    eps, 1 - eps\n",
    ")\n",
    "\n",
    "# Combine with sweep top points and best_x\n",
    "candidates = np.vstack([\n",
    "    top_sweep_points,\n",
    "    local_candidates,\n",
    "    best_x.reshape(1, -1)\n",
    "])\n",
    "\n",
    "print(\"\\nCandidate next points to evaluate:\")\n",
    "for i, c in enumerate(candidates):\n",
    "    print(f\"{i+1}: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
