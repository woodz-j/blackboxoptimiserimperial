{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- Initial data ---\n",
    "X_init = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ]\n",
    "])\n",
    "\n",
    "y_init = np.array([0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "                   0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "                   -0.01385762, 0.61120522])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new observation\n",
    "X_new = np.array([[0.365139, 0.474667]])\n",
    "y_new = np.array([-0.006080823079048435])\n",
    "\n",
    "# Combine with previous data\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])\n",
    "\n",
    "X_init = X_all\n",
    "y_init = y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_init)\n",
    "print(X_init.shape)   # Useful if it’s an array\n",
    "print(type(X_init)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_init)\n",
    "print(y_init.shape)   # Useful if it’s an array\n",
    "print(type(y_init)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Fit a Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = sigma[0]\n",
    "    mu = mu[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    from scipy.stats import norm\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "y_best = y_init.max()\n",
    "bounds = [(0,1), (0,1)]\n",
    "\n",
    "res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "               x0=np.random.rand(2),\n",
    "               bounds=bounds,\n",
    "               method='L-BFGS-B')\n",
    "\n",
    "x_next = res.x\n",
    "print(\"Next point to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly increase alpha (the noise level) since the function outputs are noisy\n",
    "# --- Fit a Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_init, y_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Expected Improvement acquisition function ---\n",
    "# change xi to 0.01\n",
    "def expected_improvement(x, gp, y_best, xi=0.05):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = sigma[0]\n",
    "    mu = mu[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    from scipy.stats import norm\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "y_best = y_all.max()\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "\n",
    "def propose_location(acquisition, gp, y_best, bounds, n_restarts=25):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    for i in range(n_restarts):\n",
    "        x0 = np.random.rand(2)\n",
    "        res = minimize(lambda x: acquisition(x, gp, y_best),\n",
    "                       x0=x0,\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B')\n",
    "        if res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "x_next = propose_location(expected_improvement, gp, y_best, bounds)\n",
    "print(\"Next point to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Initial data ---\n",
    "X_init = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ]\n",
    "])\n",
    "\n",
    "y_init = np.array([0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "                   0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "                   -0.01385762, 0.61120522])\n",
    "\n",
    "# --- Add new observations (example: last evaluated points) ---\n",
    "X_new = np.array([\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777]\n",
    "])\n",
    "y_new = np.array([-0.006080823079048435, 0.6741068207629037])\n",
    "\n",
    "# Combine all data\n",
    "X_all = np.vstack((X_init, X_new))\n",
    "y_all = np.hstack((y_init, y_new))\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Expected Improvement ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.05):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize\n",
    "\n",
    "# --- Acquisition optimizer with multiple restarts ---\n",
    "def propose_location(acquisition, gp, y_best, bounds, n_restarts=25):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(2)\n",
    "        res = minimize(lambda x: acquisition(x, gp, y_best),\n",
    "                       x0=x0,\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B')\n",
    "        if res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# --- Select next point ---\n",
    "y_best = y_all.max()\n",
    "bounds = [(0,1), (0,1)]\n",
    "x_next = propose_location(expected_improvement, gp, y_best, bounds)\n",
    "\n",
    "print(\"Next point to evaluate:\", x_next)\n",
    "\n",
    "# Print with 6 decimal places\n",
    "x_next_rounded = np.round(x_next, 6)\n",
    "print(\"Next point to evaluate (6 decimal places):\", x_next_rounded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "New point: [0.242364, 0.231669]\n",
    "Output: -0.014065\n",
    "This new point is far from the current best in input space (closer to the bottom-left corner).\n",
    "Its negative output confirms that this region is not promising.\n",
    "The GP surrogate model will now learn low predicted values in this area and also reduce uncertainty near this point.\n",
    "✅ So this observation primarily helps exploration: it teaches the model where not to sample, which reduces wasted evaluations in low-value regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669]  # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521  # Latest output\n",
    "])\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Expected Improvement ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.05):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]\n",
    "    sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative because we will minimize\n",
    "\n",
    "# --- Acquisition optimizer with multiple random restarts ---\n",
    "def propose_location(acquisition, gp, y_best, bounds, n_restarts=25):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(2)\n",
    "        res = minimize(lambda x: acquisition(x, gp, y_best),\n",
    "                       x0=x0,\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B')\n",
    "        if res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# --- Select next point ---\n",
    "y_best = y_all.max()  # 0.6741068\n",
    "bounds = [(0,1), (0,1)]\n",
    "x_next = propose_location(expected_improvement, gp, y_best, bounds)\n",
    "\n",
    "# Print next point to 6 decimal places\n",
    "x_next_rounded = np.round(x_next, 6)\n",
    "print(\"Next point to evaluate (6 decimal places):\", x_next_rounded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "- The new y ≈ 0.0185 is small positive — better than many negative samples but far below your best (0.6741).\n",
    "- This is useful exploration data: it helps the GP rule out parts of the space that are unlikely to contain the global maximum.\n",
    "- 2 options:\n",
    "- Exploit / refine around the current best — use EI with a small xi (e.g. xi = 0.01) to fine-tune near the highest region and try to improve the best value.\n",
    "- Explore a nearby promising region — use EI with a larger xi (e.g. xi = 0.2) or UCB to push into uncertain regions (for example near [0.438,0.685] or between [0.438,0.685] and [0.511,0.507]) and check for another peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- X_all, y_all should already include the latest point [0.199598,0.656821] -> 0.018456695795070272\n",
    "\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "def expected_improvement(x, gp, y_best, xi):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]; sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei\n",
    "\n",
    "def propose_location(acquisition, gp, y_best, bounds, xi, n_restarts=40):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.rand(2)\n",
    "        res = minimize(lambda x: acquisition(x, gp, y_best, xi),\n",
    "                       x0=x0,\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "y_best = y_all.max()\n",
    "bounds = [(0,1),(0,1)]\n",
    "\n",
    "# Exploit candidate (low xi)\n",
    "x_exploit = propose_location(expected_improvement, gp, y_best, bounds, xi=0.01, n_restarts=50)\n",
    "\n",
    "# Explore candidate (higher xi)\n",
    "x_explore = propose_location(expected_improvement, gp, y_best, bounds, xi=0.20, n_restarts=50)\n",
    "\n",
    "# Round to 6 decimals\n",
    "print(\"Exploit (6 d.p.):\", np.round(x_exploit, 6))\n",
    "print(\"Explore (6 d.p.):\", np.round(x_explore, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "- With only one evaluation, pick a point that maximises the chance of improving the current best (0.6741 at [0.511479, 0.507777]) — i.e. a local, high-confidence exploit pick rather than broad exploration.\n",
    "- Going with Exploit (6 d.p.): [0.425763 0.235879]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "- The new y ≈ 0.12647 is better than the negative samples nearby but worse than the nearest moderately-good neighbor (0.21496 at [0.4546,0.2905]).\n",
    "- Being close (dist ≈ 0.062) to that moderately-good point means this neighborhood is partially promising but not a hot spot compared with the global best.\n",
    "- The observation will reduce posterior uncertainty around [0.43,0.24] and push the GP mean to reflect a moderate value in that region. - In practical terms, the GP is less likely to re-sample that exact spot and will prefer either (a) fine-tuning near the global best, or (b) searching nearby uncertain regions that could connect moderate regions to the best.\n",
    "- Conclusion: this point helps rule out the bottom-right of the moderate cluster as the global maximizer — it’s useful negative evidence for large gains there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821],\n",
    "    [0.425763, 0.235879] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272,\n",
    "    0.12646677030059522 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "- Exploit. Use EI with a small xi (e.g. xi=0.01) and many restarts, seeded with the current best, to produce a local-improvement candidate near [0.511479,0.507777].\n",
    "- That has the highest chance to raise maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- assume X_all, y_all already include the latest point [0.425763,0.235879] -> 0.12646677030059522\n",
    "\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]; sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei\n",
    "\n",
    "def propose_exploit(gp, y_best, bounds=[(0,1),(0,1)], n_restarts=200):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    starts = [np.array([0.511479, 0.507777])]  # current best\n",
    "    starts += [np.random.rand(2) for _ in range(n_restarts-1)]\n",
    "    for x0 in starts:\n",
    "        res = minimize(lambda x: expected_improvement(x, gp, y_best, xi=0.01),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "y_best = y_all.max()\n",
    "x_next = propose_exploit(gp, y_best, n_restarts=200)\n",
    "print(\"Exploit next (6 d.p.):\", np.round(x_next, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Week 7\n",
    "New point: [0.517484, 0.513827] → y = 0.5750720845426626.\n",
    "This is high and close to current best (0.6741068 at [0.511479, 0.507777]), but not a new maximum.\n",
    "It confirms a strong peak in that region — the GP will now be more confident there (lower σ) and predict high mean nearby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821],\n",
    "    [0.425763, 0.235879],\n",
    "    [0.517484, 0.513827] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272,\n",
    "    0.12646677030059522, \n",
    "    0.5750720845426626 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Do a local refinement around the best point. Run EI with a small xi (0.01 or 0.005), seed starts with the current best [0.511479, 0.507777] and include the new point as a seed. If optimization returns a point almost identical to the best (within ~1e-3), return a small jittered point around the best (Gaussian jitter scale ~0.01 clipped to [0,1]) to explore the immediate neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# assume X_all, y_all exist and contain previous points\n",
    "\n",
    "# --- Fit GP ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Expected Improvement (small xi for exploitation) ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]; sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei\n",
    "\n",
    "# --- Propose exploit: many restarts, seed current best & new point ---\n",
    "def propose_exploit(gp, y_best, best_seed, new_seed, bounds=[(0,1),(0,1)], n_restarts=200):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    starts = [np.array(best_seed), np.array(new_seed)] + [np.random.rand(2) for _ in range(n_restarts-2)]\n",
    "    for x0 in starts:\n",
    "        res = minimize(lambda x: expected_improvement(x, gp, y_best, xi=0.01),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    # if result is almost identical to best_seed, jitter slightly\n",
    "    if np.linalg.norm(best_x - np.array(best_seed)) < 1e-3:\n",
    "        jitter = np.random.normal(scale=0.01, size=2)\n",
    "        best_x = np.clip(np.array(best_seed) + jitter, 0.0, 1.0)\n",
    "    return best_x\n",
    "\n",
    "y_best = y_all.max()\n",
    "best_seed = [0.511479, 0.507777]   # prior best\n",
    "new_seed = [0.517484, 0.513827]    # latest point\n",
    "\n",
    "x_next = propose_exploit(gp, y_best, best_seed, new_seed, n_restarts=200)\n",
    "print(\"Next exploit (6 d.p.):\", np.round(x_next, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "If I still don’t exceed 0.6741 after a couple of local refinements, then switch to exploration (increase xi or try UCB or sample the other high-value cluster) because the local peak may be exhausted or noise-limited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "- Confirms a high-value region around ~[0.51,0.51].\n",
    "- With three nearby high observations, posterior variance (σ) around ~[0.51,0.52] will be low. Expected Improvement (EI) will therefore require tighter, local improvements to beat the best; the acquisition surface tends to produce candidates that are either tiny refinements near the best or else search elsewhere for high uncertainty.\n",
    "- EI with a small xi will exploit (fine-tune) around the [0.51,0.51] region.\n",
    "- to find other peaks, I must force exploration (increase xi, use UCB, or occasionally sample a random high-uncertainty point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821],\n",
    "    [0.425763, 0.235879],\n",
    "    [0.517484, 0.513827],\n",
    "    [0.521491, 0.517865] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272,\n",
    "    0.12646677030059522, \n",
    "    0.5750720845426626,\n",
    "    0.5531590730253101 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# --- Fit GP ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Expected Improvement (small xi for exploitation) ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]; sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei\n",
    "\n",
    "# --- Propose local exploit: seed with best and latest point ---\n",
    "def propose_local_exploit(gp, y_best, seeds, bounds=[(0,1),(0,1)], n_restarts=150):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    starts = seeds + [np.random.rand(2) for _ in range(n_restarts - len(seeds))]\n",
    "    for x0 in starts:\n",
    "        res = minimize(lambda x: expected_improvement(x, gp, y_best, xi=0.01),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    # if optimizer returns point nearly identical to best seed, jitter slightly:\n",
    "    if np.linalg.norm(best_x - seeds[0]) < 1e-3:\n",
    "        print(\"jitterbug\")\n",
    "        best_x = np.clip(seeds[0] + np.random.normal(scale=0.008, size=2), 0.0, 1.0)\n",
    "    return best_x\n",
    "\n",
    "y_best = y_all.max()\n",
    "best_seed = np.array([0.511479, 0.507777])   # prior best\n",
    "new_seed  = np.array([0.521491, 0.517865])   # latest point\n",
    "\n",
    "x_next = propose_local_exploit(gp, y_best, seeds=[best_seed, new_seed], n_restarts=150)\n",
    "print(\"Exploit next (6 d.p.):\", np.round(x_next, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- All observed data points ---\n",
    "X_all = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.7786275 ],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "    [0.70263656, 0.9265642 ],\n",
    "    [0.365139, 0.474667],\n",
    "    [0.511479, 0.507777],\n",
    "    [0.242364, 0.231669],\n",
    "    [0.199598, 0.656821],\n",
    "    [0.425763, 0.235879],\n",
    "    [0.517484, 0.513827],\n",
    "    [0.521491, 0.517865],\n",
    "    [0.529509, 0.525943] # Latest observation\n",
    "])\n",
    "\n",
    "y_all = np.array([\n",
    "    0.53899612, 0.42058624, -0.06562362, 0.29399291, \n",
    "    0.21496451, 0.02310555, 0.24461934, 0.03874902, \n",
    "    -0.01385762, 0.61120522,\n",
    "    -0.006080823079048435,\n",
    "    0.6741068207629037,\n",
    "    -0.014065043301466521,\n",
    "    0.018456695795070272,\n",
    "    0.12646677030059522, \n",
    "    0.5750720845426626,\n",
    "    0.5531590730253101,\n",
    "    0.6221952072714012 # Latest output\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "- New observation: [0.529509, 0.525943] → y = 0.6221952072714012.\n",
    "- This is the second-best observation so far (behind 0.6741068 at [0.511479,0.507777]).\n",
    "- It strengthens the view that the global maximum lies in the ~[0.51,0.53] × [0.51,0.53] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Fit GP ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# --- Expected Improvement (small xi for exploitation) ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu = mu[0]; sigma = sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei\n",
    "\n",
    "# --- Propose exploit: seed with best and recent highs ---\n",
    "def propose_exploit(gp, y_best, seeds, bounds=[(0,1),(0,1)], n_restarts=200):\n",
    "    best_x = None\n",
    "    best_acq = 1e10\n",
    "    starts = seeds + [np.random.rand(2) for _ in range(n_restarts - len(seeds))]\n",
    "    for x0 in starts:\n",
    "        res = minimize(lambda x: expected_improvement(x, gp, y_best, xi=0.01),\n",
    "                       x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.success and res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    # small jitter if returned point is nearly identical to first seed\n",
    "    if np.linalg.norm(best_x - seeds[0]) < 1e-3:\n",
    "        best_x = np.clip(seeds[0] + np.random.normal(scale=0.008, size=2), 0, 1)\n",
    "    return best_x\n",
    "\n",
    "y_best = y_all.max()\n",
    "seeds = [np.array([0.511479, 0.507777]), np.array([0.521491, 0.517865]), np.array([0.517484, 0.513827])]\n",
    "x_next = propose_exploit(gp, y_best, seeds=seeds, n_restarts=200)\n",
    "print(\"Next exploit (6 d.p.):\", np.round(x_next, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
