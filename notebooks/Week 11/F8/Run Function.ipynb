{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datain)\n",
    "print(datain.shape)   # Useful if it’s an array\n",
    "print(type(datain)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataout)\n",
    "print(dataout.shape)   # Useful if it’s an array\n",
    "print(type(dataout)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -------------------------\n",
    "# Put your data here\n",
    "# -------------------------\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "# -------------------------\n",
    "# Transform / settings\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_init.shape[1])  # assume normalized [0,1] per dim\n",
    "dim = X_init.shape[1]\n",
    "y_best = y_init.max()\n",
    "\n",
    "# -------------------------\n",
    "# Fit GP surrogate\n",
    "# -------------------------\n",
    "kernel = Matern(length_scale=np.ones(dim),\n",
    "                length_scale_bounds=(1e-2, 1e2),\n",
    "                nu=2.5)\n",
    "# alpha = noise variance. If outputs are noisy, increase alpha (e.g. 1e-4 or tuned)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=5, random_state=0)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# -------------------------\n",
    "# Expected Improvement (EI)\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei  # note: maximize this\n",
    "\n",
    "# Negative EI for minimizers\n",
    "def neg_ei(x, gp, y_best, xi=0.01):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Acquisition optimization: many random starts + DE fallback\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40):\n",
    "    dim = bounds.shape[0]\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    # Random-start L-BFGS-B\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Try differential evolution as a global check (optional, slower)\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best),\n",
    "                                       bounds=bounds.tolist(),\n",
    "                                       maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # clamp to bounds and return\n",
    "    best_x = np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "    return best_x\n",
    "\n",
    "# -------------------------\n",
    "# If you need a small batch (greedy sequential EI)\n",
    "# -------------------------\n",
    "def propose_batch(gp, y_best, bounds, batch_size=3):\n",
    "    batch = []\n",
    "    gp_copy = gp\n",
    "    X_aug = X_init.copy()\n",
    "    y_aug = y_init.copy()\n",
    "    for i in range(batch_size):\n",
    "        x_next = propose_location(gp_copy, y_aug.max(), bounds)\n",
    "        # \"Fake\" evaluation: use GP predicted mean (Kriging believer)\n",
    "        y_fake = gp_copy.predict(x_next.reshape(1, -1))[0]\n",
    "        # Append to augmented set and refit GP (greedy sequential)\n",
    "        X_aug = np.vstack([X_aug, x_next])\n",
    "        y_aug = np.hstack([y_aug, y_fake])\n",
    "        gp_copy = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "        gp_copy.fit(X_aug, y_aug)\n",
    "        batch.append(x_next)\n",
    "    return np.array(batch)\n",
    "\n",
    "# -------------------------\n",
    "# Run proposal\n",
    "# -------------------------\n",
    "x_next = propose_location(gp, y_best, np.array(bounds))\n",
    "print(\"Suggested next point (continuous):\", x_next)\n",
    "\n",
    "# If some dims are categorical/encoded, round or map them here, e.g.:\n",
    "# x_next[cat_index] = int(np.round(x_next[cat_index] * (num_categories-1)))\n",
    "#\n",
    "# Example: If dim 6 encodes optimizer 0..3:\n",
    "# x_next[6] = int(np.round(x_next[6] * 3))\n",
    "\n",
    "# -------------------------\n",
    "# (Optional) propose a small batch\n",
    "# -------------------------\n",
    "batch = propose_batch(gp, y_best, np.array(bounds), batch_size=3)\n",
    "print(\"Suggested batch of 3 points (continuous):\\n\", batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Initial data ---\n",
    "#X_init = np.array([...])  # 30x6 array\n",
    "#y_init = np.array([...])  # 30 outputs\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "y_best = y_init.max()  # best performance so far\n",
    "\n",
    "# --- Fit Gaussian Process ---\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_init, y_init)\n",
    "\n",
    "# --- Expected Improvement acquisition function ---\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    mu, sigma = mu[0], sigma[0]\n",
    "    if sigma == 0.0:\n",
    "        return 0.0\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return -ei  # negative for minimization in scipy\n",
    "\n",
    "# --- Optimize acquisition function ---\n",
    "bounds = [(0,1)]*6\n",
    "best_x = None\n",
    "best_ei = float('inf')\n",
    "\n",
    "for _ in range(20):  # multiple random starts\n",
    "    x0 = np.random.rand(6)\n",
    "    res = minimize(lambda x: expected_improvement(x, gp, y_best),\n",
    "                   x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_ei:\n",
    "        best_ei = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "x_next = best_x\n",
    "print(\"Next hyperparameter set to try:\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "# -------------------------\n",
    "# Existing data (your previous iteration)\n",
    "# -------------------------\n",
    "X_init = datain\n",
    "y_init = dataout\n",
    "\n",
    "# Latest evaluated point (the one that gave 9.68029...)\n",
    "X_new = np.array([[0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362]])\n",
    "y_new = np.array([9.6802928063541])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: Fit updated GP surrogate\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_all.shape[1])\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(length_scale=np.ones(dim),\n",
    "                length_scale_bounds=(1e-2, 1e2),\n",
    "                nu=2.5)\n",
    "\n",
    "# Lower alpha for smooth deterministic behavior\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6,\n",
    "                              normalize_y=True, n_restarts_optimizer=5,\n",
    "                              random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Expected Improvement (EI) — exploitative mode\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):  # smaller xi = exploit\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Optimize acquisition to find next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40):\n",
    "    best_x, best_val = None, 1e20\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best, 0.001),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val, best_x = res.fun, res.x\n",
    "\n",
    "    # Optional global search (safety)\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best, 0.001),\n",
    "                                        bounds=bounds.tolist(),\n",
    "                                        maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val, best_x = de_res.fun, de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "\n",
    "# Compute updated best observed value\n",
    "y_best = y_all.max()\n",
    "\n",
    "# Get next suggested point\n",
    "x_next = propose_location(gp, y_best, bounds)\n",
    "\n",
    "print(\"Next suggested point (exploit mode):\", x_next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "# -------------------------\n",
    "# Existing data (your previous iteration)\n",
    "# -------------------------\n",
    "X_init = datain\n",
    "y_init = dataout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest evaluated point (the one that gave 9.68029...) from Week 1\n",
    "X_new = np.array([[0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362]])\n",
    "y_new = np.array([9.6802928063541])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest evaluated point (the one that gave 9.62007...) from Week 2\n",
    "X_new = np.array([[0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999]])\n",
    "y_new = np.array([9.6200730832974])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all)\n",
    "print(X_all.shape)   # Useful if it’s an array\n",
    "print(type(X_all)) \n",
    "print(\"-----------------------------------------------\")\n",
    "print(y_all)\n",
    "print(y_all.shape)   # Useful if it’s an array\n",
    "print(type(y_all)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 2: Fit updated GP surrogate\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_all.shape[1])\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(length_scale=np.ones(dim),\n",
    "                length_scale_bounds=(1e-2, 1e2),\n",
    "                nu=2.5)\n",
    "\n",
    "# Lower alpha for smooth deterministic behavior\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6,\n",
    "                              normalize_y=True, n_restarts_optimizer=5,\n",
    "                              random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Expected Improvement (EI) — exploitative mode\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):  # smaller xi = exploit\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Optimize acquisition to find next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40):\n",
    "    best_x, best_val = None, 1e20\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best, 0.001),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val, best_x = res.fun, res.x\n",
    "\n",
    "    # Optional global search (safety)\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best, 0.001),\n",
    "                                        bounds=bounds.tolist(),\n",
    "                                        maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val, best_x = de_res.fun, de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "\n",
    "# Compute updated best observed value\n",
    "y_best = y_all.max()\n",
    "\n",
    "# Get next suggested point\n",
    "x_next = propose_location(gp, y_best, bounds)\n",
    "\n",
    "print(\"Next suggested point (exploit mode):\", x_next)\n",
    "\n",
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Slight tweak to slightly shrink the search bounds to avoid exact 0 or 1 values,\n",
    "# without adding any penalties or acquisition modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated propose_location() function with the soft clamping fix integrated.\n",
    "# This will stop 0.0 and 1.0 values, while leaving everything else about your Bayesian optimization loop unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 4: Optimize EI to get next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40, xi=0.001):\n",
    "    dim = bounds.shape[0]\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    # Random-start L-BFGS-B local optimization\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B',\n",
    "            options={'maxiter': 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Global backup using Differential Evolution\n",
    "    try:\n",
    "        de_res = differential_evolution(\n",
    "            lambda x: neg_ei(x, gp, y_best, xi),\n",
    "            bounds=bounds.tolist(),\n",
    "            maxiter=200,\n",
    "            polish=True,\n",
    "            seed=0\n",
    "        )\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Soft clamp to avoid hitting exact edges\n",
    "    # --------------------------------------\n",
    "    epsilon = 0.01  # safety margin\n",
    "    best_x = np.clip(best_x, epsilon, 1 - epsilon)\n",
    "\n",
    "    return best_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 2: Fit updated GP surrogate\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_all.shape[1])\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(length_scale=np.ones(dim),\n",
    "                length_scale_bounds=(1e-2, 1e2),\n",
    "                nu=2.5)\n",
    "\n",
    "# Lower alpha for smooth deterministic behavior\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6,\n",
    "                              normalize_y=True, n_restarts_optimizer=5,\n",
    "                              random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Expected Improvement (EI) — exploitative mode\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):  # smaller xi = exploit\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Optimize acquisition to find next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40):\n",
    "    best_x, best_val = None, 1e20\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best, 0.001),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val, best_x = res.fun, res.x\n",
    "\n",
    "    # Optional global search (safety)\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best, 0.001),\n",
    "                                        bounds=bounds.tolist(),\n",
    "                                        maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val, best_x = de_res.fun, de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "\n",
    "# Compute updated best observed value\n",
    "y_best = y_all.max()\n",
    "\n",
    "# Get next suggested point\n",
    "x_next = propose_location(gp, y_best, bounds)\n",
    "\n",
    "print(\"Next suggested point (exploit mode):\", x_next)\n",
    "\n",
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded:\", x_next_6dp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: ran Week 3 with missing data accidentally (41 inputs not 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Previous high outputs: 9.6803, 9.6201\n",
    "This new point improves the current best: y_best = 9.7668\n",
    "The point is near previous high regions, especially in dimensions 4, 5, and 8 which are now close to the edges (0.01 / 0.99 after clamping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "# -------------------------\n",
    "# Existing data (your previous iteration)\n",
    "# -------------------------\n",
    "X_init = datain\n",
    "y_init = dataout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest evaluated point (the one that gave 9.68029...) from Week 1\n",
    "X_new = np.array([[0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362]])\n",
    "y_new = np.array([9.6802928063541])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_init, X_new])\n",
    "y_all = np.concatenate([y_init, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest evaluated point (the one that gave 9.62007...) from Week 2\n",
    "X_new = np.array([[0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999]])\n",
    "y_new = np.array([9.6200730832974])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_all, X_new])\n",
    "y_all = np.concatenate([y_all, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest evaluated point (the one that gave 9.766762...) from Week 3\n",
    "X_new = np.array([[0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000]])\n",
    "y_new = np.array([9.766762063933])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_all, X_new])\n",
    "y_all = np.concatenate([y_all, y_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all)\n",
    "print(X_all.shape)   # Useful if it’s an array\n",
    "print(type(X_all)) \n",
    "print(\"-----------------------------------------------\")\n",
    "print(y_all)\n",
    "print(y_all.shape)   # Useful if it’s an array\n",
    "print(type(y_all)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Summary\n",
    "The new output confirms a rising trend toward a local maximum.\n",
    "Strategy: continue local exploitation near the current best.\n",
    "Maintain safety margins (clamped bounds) and low xi.\n",
    "Each iteration: append new (X, y), refit GP, maximize EI → next point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 4: Optimize EI to get next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40, xi=0.001):\n",
    "    dim = bounds.shape[0]\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    # Random-start L-BFGS-B local optimization\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B',\n",
    "            options={'maxiter': 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Global backup using Differential Evolution\n",
    "    try:\n",
    "        de_res = differential_evolution(\n",
    "            lambda x: neg_ei(x, gp, y_best, xi),\n",
    "            bounds=bounds.tolist(),\n",
    "            maxiter=200,\n",
    "            polish=True,\n",
    "            seed=0\n",
    "        )\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Soft clamp to avoid hitting exact edges\n",
    "    # --------------------------------------\n",
    "    epsilon = 0.01  # safety margin\n",
    "    best_x = np.clip(best_x, epsilon, 1 - epsilon)\n",
    "\n",
    "    return best_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 2: Fit Gaussian Process\n",
    "# -------------------------\n",
    "bounds = np.array([(0.0, 1.0)] * X_all.shape[1])\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(length_scale=np.ones(dim), \n",
    "                length_scale_bounds=(1e-2, 1e2), \n",
    "                nu=2.5)\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=5,\n",
    "                              random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# -------------------------\n",
    "# Step 3: Expected Improvement (EI)\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x, gp, y_best, xi)\n",
    "\n",
    "# -------------------------\n",
    "# Step 4: Optimize EI to get next candidate (propose location above)\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Step 5: Get next point (exploitative mode)\n",
    "# -------------------------\n",
    "y_best = y_all.max()\n",
    "x_next = propose_location(gp, y_best, bounds, n_restarts=40, xi=0.001)\n",
    "\n",
    "print(\"Next suggested point (exploit mode, safe bounds):\", x_next)\n",
    "\n",
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume previous additions have been executed\n",
    "# Latest evaluated point (the one that gave 9.37782...) from Week 4\n",
    "X_new = np.array([[0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000]])\n",
    "y_new = np.array([9.377829603931])\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Append new data\n",
    "# -------------------------\n",
    "X_all = np.vstack([X_all, X_new])\n",
    "y_all = np.concatenate([y_all, y_new])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "This new point produced a lower output (9.3778) than your current best (9.7668). It is not near the current best in input space (Euclidean distance ≈ 1.20) — in particular it flips several coordinates relative to the best (most notably dimension 8 and 6). So this evaluation is negative evidence for that region: it helps the GP learn the shape of the surface (it reduces uncertainty and lowers predicted mean where those coordinate changes occur). The practical consequence is: don’t switch strategy — append & refit the GP, then continue exploitative local refinement around the true best, while (optionally) doing a small amount of targeted exploration to test sensitive dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "- Current best (so far): X_best ≈ [0.251068, 0.078758, 0.302102, 0.01, 0.99, 0.357561, 0.178631, 0.01] → y_best = 9.766762063933\n",
    "- New point: X_new = [0.122075, 0.01, 0.420807, 0.01, 0.839488, 0.99, 0.01, 0.99] → y_new = 9.377829603931\n",
    "- the biggest flips (dim 8 and dim 6) correlate with a drop in performance — a sign those coordinates are sensitive and likely important to the local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Step 4: Optimize EI to get next candidate\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=40, xi=0.001):\n",
    "    dim = bounds.shape[0]\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    # Random-start L-BFGS-B local optimization\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B',\n",
    "            options={'maxiter': 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Global backup using Differential Evolution\n",
    "    try:\n",
    "        de_res = differential_evolution(\n",
    "            lambda x: neg_ei(x, gp, y_best, xi),\n",
    "            bounds=bounds.tolist(),\n",
    "            maxiter=200,\n",
    "            polish=True,\n",
    "            seed=0\n",
    "        )\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # --------------------------------------\n",
    "    # Soft clamp to avoid hitting exact edges\n",
    "    # --------------------------------------\n",
    "    epsilon = 0.01  # safety margin\n",
    "    best_x = np.clip(best_x, epsilon, 1 - epsilon)\n",
    "\n",
    "    return best_x\n",
    "\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x, gp, y_best, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = np.array([(0.0, 1.0)] * X_all.shape[1])\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(length_scale=np.ones(dim), \n",
    "                length_scale_bounds=(1e-2, 1e2), \n",
    "                nu=2.5)\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=5,\n",
    "                              random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "append point, refit GP, then propose next point using a local search around current best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Build local bounds around x_best\n",
    "local_radius = 0.12  # change 0.08-0.15 to tune locality\n",
    "eps = 1e-3\n",
    "dim = X_all.shape[1]\n",
    "local_bounds = []\n",
    "for i in range(dim):\n",
    "    low = max(eps, x_best[i] - local_radius)\n",
    "    high = min(1 - eps, x_best[i] + local_radius)\n",
    "    # If a coordinate is already very tight (e.g. near 0.01/0.99), keep it tighter:\n",
    "    if x_best[i] <= 0.02 or x_best[i] >= 0.98:\n",
    "        # keep small wiggle\n",
    "        low = max(eps, x_best[i] - 0.02)\n",
    "        high = min(1 - eps, x_best[i] + 0.02)\n",
    "    local_bounds.append((low, high))\n",
    "local_bounds = np.array(local_bounds)\n",
    "\n",
    "# Propose next point (exploitative EI)\n",
    "x_next = propose_location(gp, y_best, local_bounds, n_restarts=20, xi=0.001)\n",
    "\n",
    "print(\"x_best (current):\", x_best)\n",
    "print(\"y_best:\", y_best)\n",
    "print(\"Next candidate (local exploit):\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "x_next_6dp\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# Week 6\n",
    "- good news: the new evaluation is better than the previous best and it validates the direction of the local search.\n",
    "- New point: [0.214679, 0.179152, 0.182102, 0.01, 0.99, 0.278369, 0.298631, 0.01]\n",
    "- New output: 9.823667311119 → new best (previous best was 9.766762063933)\n",
    "- further confirmation of a local optimum region — the search is correctly refining the peak rather than wandering off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load original data\n",
    "# ------------------------------------------------------------\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Append new evaluations (in chronological order)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "new_points = [\n",
    "    ([0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362], 9.6802928063541),\n",
    "    ([0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999], 9.6200730832974),\n",
    "    ([0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000], 9.766762063933),\n",
    "    ([0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000], 9.377829603931),\n",
    "    ([0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000], 9.823667311119),\n",
    "]\n",
    "\n",
    "for x, y in new_points:\n",
    "    X_all = np.vstack([X_all, np.array(x)])\n",
    "    y_all = np.append(y_all, y)\n",
    "\n",
    "print(\"Initialisation complete.\")\n",
    "print(\"X_all shape:\", X_all.shape)\n",
    "print(\"y_all shape:\", y_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_all)\n",
    "print(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Previous four evaluated points and outputs\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Fit GP surrogate (GP hyperparameters auto-tuned at fit)\n",
    "# ------------------------------------------------------------\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Expected Improvement (EI)\n",
    "# ------------------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = x.reshape(1, -1)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = sigma.reshape(-1) + 1e-9\n",
    "    Z = (mu - y_best - xi) / sigma\n",
    "    from scipy.stats import norm\n",
    "    return (mu - y_best - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x, gp, y_best, xi)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Acquisition optimizer (multi-start)\n",
    "# ------------------------------------------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=30, xi=0.001):\n",
    "    best_x = None\n",
    "    best_acq = np.inf\n",
    "    dim = bounds.shape[0]\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\"\n",
    "        )\n",
    "        if res.fun < best_acq:\n",
    "            best_acq = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Build local bounds around the current best\n",
    "# ------------------------------------------------------------\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "local_radius = 0.08\n",
    "eps = 1e-3\n",
    "bounds = []\n",
    "\n",
    "for val in x_best:\n",
    "    low = max(eps, val - local_radius)\n",
    "    high = min(1 - eps, val + local_radius)\n",
    "    bounds.append((low, high))\n",
    "\n",
    "bounds = np.array(bounds)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Propose next candidate (exploitation mode)\n",
    "# ------------------------------------------------------------\n",
    "x_next = propose_location(gp, y_best, bounds, n_restarts=30, xi=0.001)\n",
    "\n",
    "print(\"Current best point:\", x_best)\n",
    "print(\"Current best value:\", y_best)\n",
    "print(\"Next candidate to evaluate:\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Week 7\n",
    "- New point: [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000]\n",
    "- New output: 9.935498490899 → new best so far (previous best was 9.823667311119)\n",
    "- this suggests the true optimum region may be slightly offset from the previous local peak, and the GP exploitation strategy is correctly honing in on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -------------------------\n",
    "# Initial dataset\n",
    "# -------------------------\n",
    "datain = np.load('initial_inputs.npy')\n",
    "dataout = np.load('initial_outputs.npy')\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# -------------------------\n",
    "# Previous submissions\n",
    "# -------------------------\n",
    "previous_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000]\n",
    "])\n",
    "\n",
    "previous_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899\n",
    "])\n",
    "\n",
    "# Append previous submissions\n",
    "X_all = np.vstack([X_all, previous_points])\n",
    "y_all = np.concatenate([y_all, previous_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "- The optimisation strategy is working hierarchically:\n",
    "- Base-level parameters set the region,\n",
    "- Higher-level parameters refine the optimum.\n",
    "- The latest result shows the true peak may be slightly shifted from prior corner-edge assumptions, which is why local refinement is crucial.\n",
    "- The GP is learning this automatically, and acquisition function (EI) exploitation is producing consistently better points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# -------------------------\n",
    "# Fit GP surrogate\n",
    "# -------------------------\n",
    "dim = X_all.shape[1]\n",
    "kernel = Matern(length_scale=np.ones(dim), length_scale_bounds=(1e-2, 1e2), nu=2.5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True,\n",
    "                              n_restarts_optimizer=5, random_state=0)\n",
    "gp.fit(X_all, y_all)\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "# -------------------------\n",
    "# Expected Improvement (EI)\n",
    "# -------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi=xi)[0]\n",
    "\n",
    "# -------------------------\n",
    "# Acquisition optimisation\n",
    "# -------------------------\n",
    "def propose_location(gp, y_best, bounds, n_restarts=30, xi=0.001):\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun=neg_ei,\n",
    "                       x0=x0,\n",
    "                       args=(gp, y_best, xi),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       options={'maxiter':200})\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    try:\n",
    "        de_res = differential_evolution(lambda x: neg_ei(x, gp, y_best, xi),\n",
    "                                       bounds=bounds.tolist(),\n",
    "                                       maxiter=200, polish=True, seed=0)\n",
    "        if de_res.fun < best_val:\n",
    "            best_val = de_res.fun\n",
    "            best_x = de_res.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    best_x = np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "    return best_x\n",
    "\n",
    "# -------------------------\n",
    "# Local bounds for exploitative search\n",
    "# -------------------------\n",
    "local_radius = 0.08  # tighten for fine-tuning\n",
    "eps = 1e-3\n",
    "local_bounds = []\n",
    "for i in range(dim):\n",
    "    if x_best[i] <= 0.02 or x_best[i] >= 0.98:\n",
    "        # very small wiggle for base-level dims\n",
    "        low = max(eps, x_best[i] - 0.02)\n",
    "        high = min(1 - eps, x_best[i] + 0.02)\n",
    "    else:\n",
    "        low = max(eps, x_best[i] - local_radius)\n",
    "        high = min(1 - eps, x_best[i] + local_radius)\n",
    "    local_bounds.append((low, high))\n",
    "local_bounds = np.array(local_bounds)\n",
    "\n",
    "# -------------------------\n",
    "# Propose next point\n",
    "# -------------------------\n",
    "x_next = propose_location(gp, y_best, local_bounds, n_restarts=30, xi=0.001)\n",
    "\n",
    "print(\"x_best (current):\", x_best)\n",
    "print(\"y_best:\", y_best)\n",
    "print(\"Next candidate (local exploit):\", x_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "# Week 8\n",
    "- x₄ ≈ 0.01–0.10\n",
    "- x₅ ≈ 0.90–1.00\n",
    "- x₈ ≈ 0.01–0.10\n",
    "- These dimensions have repeatedly locked in at the same region and seem to define the operating regime where high values occur.\n",
    "The new point continues this pattern almost exactly\n",
    "- The score (9.8838) is high but slightly below the current best (9.9355)\n",
    "- This narrows the search towards the sharply peaked maxima instead of encouraging exploration.\n",
    "- Found a promising peak, but not necessarily the global one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Load initial dataset\n",
    "# ---------------------------------------------------\n",
    "datain = np.load(\"initial_inputs.npy\")\n",
    "dataout = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Append ALL previously evaluated points\n",
    "# ---------------------------------------------------\n",
    "new_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000],\n",
    "    [0.054679, 0.080603, 0.022102, 0.068388, 0.990000, 0.427374, 0.138631, 0.010000]\n",
    "])\n",
    "\n",
    "new_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899,\n",
    "    9.883822772355\n",
    "])\n",
    "\n",
    "X_all = np.vstack([X_all, new_points])\n",
    "y_all = np.hstack([y_all, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. GP model\n",
    "# ---------------------------------------------------\n",
    "kernel = Matern(nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=8\n",
    ")\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "bounds = np.array([(0.0, 1.0)] * 8)\n",
    "y_best = y_all.max()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Expected Improvement\n",
    "# ---------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi=0.01):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    return imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.01):\n",
    "    return -expected_improvement(x, gp, y_best, xi)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Optimisation helpers\n",
    "# ---------------------------------------------------\n",
    "def optimise_acquisition(fun, bounds):\n",
    "    # Multi-start L-BFGS\n",
    "    best_x = None\n",
    "    best_val = 1e20\n",
    "    for _ in range(40):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(fun, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "    return best_x\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. Generate two candidates\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# ---- A) Exploit (small local jitter around best observed)\n",
    "best_idx = np.argmax(y_all)\n",
    "x_best = X_all[best_idx]\n",
    "\n",
    "local_bounds = np.clip(\n",
    "    np.vstack([x_best - 0.05, x_best + 0.05]).T,\n",
    "    0.0, 1.0\n",
    ")\n",
    "\n",
    "x_exploit = optimise_acquisition(\n",
    "    lambda x: neg_ei(x, gp, y_best, xi=0.001),\n",
    "    local_bounds\n",
    ")\n",
    "\n",
    "# ---- B) Explore (full global search)\n",
    "x_explore = optimise_acquisition(\n",
    "    lambda x: neg_ei(x, gp, y_best, xi=0.05),\n",
    "    bounds\n",
    ")\n",
    "\n",
    "print(\"Next EXPLOIT candidate:\", x_exploit)\n",
    "print(\"Next EXPLORE candidate:\", x_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "- Going with an EXPLORE  point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_explore, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "- [0.045771, 0.336234, 0.012812, 0.225992, 0.741620, 0.506746, 0.173188, 0.640432] -> 9.9091106001996\n",
    "- Previous best was 9.935498490899, so this is slightly lower, but still a high-performing point.\n",
    "- This point is far from the previous local optimum region in parameter space, particularly in dims 4, 5, 8 (previously ~0.09 / 0.91 / 0.09; now 0.226 / 0.742 / 0.640), and in dims 1–3 and 6–7 as well.\n",
    "- The point lies outside the previously exploited high-performance region, but still produces a high output.\n",
    "- This suggests there may be another peak or ridge in the objective landscape that we haven’t fully explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Load initial dataset\n",
    "# ---------------------------------------------------\n",
    "datain = np.load(\"initial_inputs.npy\")\n",
    "dataout = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Append ALL previously evaluated points\n",
    "# ---------------------------------------------------\n",
    "new_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000],\n",
    "    [0.054679, 0.080603, 0.022102, 0.068388, 0.990000, 0.427374, 0.138631, 0.010000],\n",
    "    [0.045771, 0.336234, 0.012812, 0.225992, 0.741620, 0.506746, 0.173188, 0.640432]\n",
    "])\n",
    "\n",
    "new_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899,\n",
    "    9.883822772355,\n",
    "    9.9091106001996\n",
    "])\n",
    "\n",
    "X_all = np.vstack([X_all, new_points])\n",
    "y_all = np.hstack([y_all, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Fit GP surrogate\n",
    "# ---------------------------------------------------\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(\n",
    "    length_scale=np.ones(dim),\n",
    "    length_scale_bounds=(1e-2, 1e2),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "# Identify best point seen so far\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Expected Improvement\n",
    "# ---------------------------------------------------\n",
    "from scipy.stats import norm\n",
    "\n",
    "def expected_improvement(x, gp, y_best, xi=0.001):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    Z = imp / sigma\n",
    "    return imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi=0.001):\n",
    "    return -expected_improvement(x, gp, y_best, xi)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Acquisition search\n",
    "# ---------------------------------------------------\n",
    "def propose_location(bounds, gp, y_best, n_restarts=25, xi=0.001):\n",
    "    best_val = 1e30\n",
    "    best_x = None\n",
    "\n",
    "    # Multi-start local optimisation\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:,0], bounds[:,1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B',\n",
    "            options={'maxiter': 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    # Differential evolution for global search\n",
    "    try:\n",
    "        res_de = differential_evolution(\n",
    "            lambda x: neg_ei(x, gp, y_best),\n",
    "            bounds=bounds,\n",
    "            maxiter=150,\n",
    "            seed=0,\n",
    "            polish=True\n",
    "        )\n",
    "        if res_de.fun < best_val:\n",
    "            best_x = res_de.x\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return np.clip(best_x, bounds[:,0], bounds[:,1])\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. EXploit bounds (local to global best)\n",
    "# ---------------------------------------------------\n",
    "eps = 1e-3\n",
    "exploit_radius = 0.08\n",
    "\n",
    "exploit_bounds = []\n",
    "for i in range(dim):\n",
    "    low = max(eps, x_best[i] - exploit_radius)\n",
    "    high = min(1 - eps, x_best[i] + exploit_radius)\n",
    "    exploit_bounds.append((low, high))\n",
    "\n",
    "exploit_bounds = np.array(exploit_bounds)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. EXplore bounds (local around the new 9.909 point)\n",
    "# ---------------------------------------------------\n",
    "x_second_peak = new_points[-1]  # the 9.909 point\n",
    "explore_radius = 0.15\n",
    "\n",
    "explore_bounds = []\n",
    "for i in range(dim):\n",
    "    low = max(eps, x_second_peak[i] - explore_radius)\n",
    "    high = min(1 - eps, x_second_peak[i] + explore_radius)\n",
    "    explore_bounds.append((low, high))\n",
    "\n",
    "explore_bounds = np.array(explore_bounds)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Generate candidates\n",
    "# ---------------------------------------------------\n",
    "x_next_exploit = propose_location(exploit_bounds, gp, y_best, n_restarts=25, xi=0.001)\n",
    "x_next_explore  = propose_location(explore_bounds,  gp, y_best, n_restarts=25, xi=0.001)\n",
    "\n",
    "print(\"Current best output:\", y_best)\n",
    "print(\"Current best point:\", x_best)\n",
    "print(\"\\nNext EXPLOIT (local refinement) candidate:\")\n",
    "print(x_next_exploit)\n",
    "print(\"\\nNext EXPLORE (test second basin) candidate:\")\n",
    "print(x_next_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "- Going with an EXPLOIT point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_next_exploit, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "This is now your highest observed value.\n",
    "- New output: 9.95459577812\n",
    "- Previous best: 9.935498490899\n",
    "- Improvement: +0.0191 → new best\n",
    "- Stay exploitative for now\n",
    "- Tight local bounds around the current best\n",
    "- Goal: see if you can push past ~9.97–9.98\n",
    "\n",
    "This evaluation confirms that the objective has a broad interior ridge rather than a boundary optimum, and that our Bayesian optimisation strategy has successfully transitioned from peak discovery to ridge refinement, with gains now approaching diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Load initial dataset\n",
    "# ---------------------------------------------------\n",
    "datain = np.load(\"initial_inputs.npy\")\n",
    "dataout = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Append ALL previously evaluated points\n",
    "# ---------------------------------------------------\n",
    "new_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000],\n",
    "    [0.054679, 0.080603, 0.022102, 0.068388, 0.990000, 0.427374, 0.138631, 0.010000],\n",
    "    [0.045771, 0.336234, 0.012812, 0.225992, 0.741620, 0.506746, 0.173188, 0.640432],\n",
    "    [0.129989, 0.237128, 0.115863, 0.170000, 0.830000, 0.407575, 0.138631, 0.170000]\n",
    "])\n",
    "\n",
    "new_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899,\n",
    "    9.883822772355,\n",
    "    9.9091106001996,\n",
    "    9.95459577812\n",
    "])\n",
    "\n",
    "X_all = np.vstack([X_all, new_points])\n",
    "y_all = np.hstack([y_all, new_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Fit GP surrogate\n",
    "# ---------------------------------------------------\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(\n",
    "    length_scale=np.ones(dim),\n",
    "    length_scale_bounds=(1e-2, 1e2),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Expected Improvement\n",
    "# ---------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    improvement = mu - y_best - xi\n",
    "    Z = improvement / sigma\n",
    "    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi)[0]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Acquisition optimizer\n",
    "# ---------------------------------------------------\n",
    "def propose_location(gp, y_best, bounds, xi, n_restarts=30):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\",\n",
    "            options={\"maxiter\": 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return np.clip(best_x, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. EXPLOIT candidate (local, low xi)\n",
    "# ---------------------------------------------------\n",
    "local_radius = 0.08\n",
    "eps = 1e-3\n",
    "\n",
    "exploit_bounds = []\n",
    "for i in range(dim):\n",
    "    if x_best[i] <= 0.02 or x_best[i] >= 0.98:\n",
    "        low = max(eps, x_best[i] - 0.02)\n",
    "        high = min(1 - eps, x_best[i] + 0.02)\n",
    "    else:\n",
    "        low = max(eps, x_best[i] - local_radius)\n",
    "        high = min(1 - eps, x_best[i] + local_radius)\n",
    "    exploit_bounds.append((low, high))\n",
    "\n",
    "exploit_bounds = np.array(exploit_bounds)\n",
    "\n",
    "x_exploit = propose_location(\n",
    "    gp,\n",
    "    y_best,\n",
    "    exploit_bounds,\n",
    "    xi=0.001,\n",
    "    n_restarts=30\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. EXPLORE candidate (global, higher xi)\n",
    "# ---------------------------------------------------\n",
    "global_bounds = np.array([(0.001, 0.999)] * dim)\n",
    "\n",
    "x_explore = propose_location(\n",
    "    gp,\n",
    "    y_best,\n",
    "    global_bounds,\n",
    "    xi=0.1,\n",
    "    n_restarts=40\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Results\n",
    "# ---------------------------------------------------\n",
    "print(\"Current best y:\", y_best)\n",
    "print(\"Current best x:\", x_best)\n",
    "print(\"\\nNext EXPLOIT candidate:\", x_exploit)\n",
    "print(\"Next EXPLORE candidate:\", x_explore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# Go with Exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_exploit, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# Week 11\n",
    "- Current best ≈ 9.9546 ([0.129989, 0.237128, 0.115863, 0.170000, 0.830000, 0.407575, 0.138631, 0.170000])\n",
    "- This point ≈ 9.9134 ([0.204502 0.182027 0.035863 0.106562 0.75     0.397148 0.125236 0.25    ])\n",
    "- Difference ≈ −0.041\n",
    "- So this is strong but not optimal — it sits just below the current peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 1. Load initial dataset\n",
    "# ---------------------------------------------------\n",
    "datain = np.load(\"initial_inputs.npy\")\n",
    "dataout = np.load(\"initial_outputs.npy\")\n",
    "\n",
    "X_all = datain.copy()\n",
    "y_all = dataout.copy()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 2. Append ALL previously evaluated points\n",
    "# ---------------------------------------------------\n",
    "new_points = np.array([\n",
    "    [0.203499, 0.167999, 0.195105, 0.035878, 0.999999, 0.999999, 0.224367, 0.498362],\n",
    "    [0.172222, 0.268299, 0.139005, 0.307855, 0.999999, 0.999999, 0.348896, 0.999999],\n",
    "    [0.251068, 0.078758, 0.302102, 0.010000, 0.990000, 0.357561, 0.178631, 0.010000],\n",
    "    [0.122075, 0.010000, 0.420807, 0.010000, 0.839488, 0.990000, 0.010000, 0.990000],\n",
    "    [0.214679, 0.179152, 0.182102, 0.010000, 0.990000, 0.278369, 0.298631, 0.010000],\n",
    "    [0.134679, 0.160603, 0.102102, 0.090000, 0.910000, 0.347374, 0.218631, 0.090000],\n",
    "    [0.054679, 0.080603, 0.022102, 0.068388, 0.990000, 0.427374, 0.138631, 0.010000],\n",
    "    [0.045771, 0.336234, 0.012812, 0.225992, 0.741620, 0.506746, 0.173188, 0.640432],\n",
    "    [0.129989, 0.237128, 0.115863, 0.170000, 0.830000, 0.407575, 0.138631, 0.170000],\n",
    "    [0.204502, 0.182027, 0.035863, 0.106562, 0.750000, 0.397148, 0.125236, 0.250000]\n",
    "])\n",
    "\n",
    "new_outputs = np.array([\n",
    "    9.6802928063541,\n",
    "    9.6200730832974,\n",
    "    9.766762063933,\n",
    "    9.377829603931,\n",
    "    9.823667311119,\n",
    "    9.935498490899,\n",
    "    9.883822772355,\n",
    "    9.9091106001996,\n",
    "    9.95459577812,\n",
    "    9.913402905816\n",
    "])\n",
    "\n",
    "X_all = np.vstack([X_all, new_points])\n",
    "y_all = np.hstack([y_all, new_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "This point lies:\n",
    "\n",
    "- Between the earlier “edge-heavy” regime (dims near 0.01 / 0.99),\n",
    "- And the newer interior optimum regime (dims 4, 5, 8 around ~0.1–0.25 / ~0.75–0.9).\n",
    "Notably:\n",
    "- Dims 4, 5, 8 are no longer at extremes → confirms that extremes were good but not optimal.\n",
    "- Dims 1–3, 6–7 remain in the narrow bands you’ve repeatedly seen in high-performing points.\n",
    "This suggests we are sampling along the same high-value manifold, not discovering a new basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# 3. Fit GP surrogate\n",
    "# ---------------------------------------------------\n",
    "dim = X_all.shape[1]\n",
    "\n",
    "kernel = Matern(\n",
    "    length_scale=np.ones(dim),\n",
    "    length_scale_bounds=(1e-2, 1e2),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "gp.fit(X_all, y_all)\n",
    "\n",
    "y_best = y_all.max()\n",
    "x_best = X_all[np.argmax(y_all)]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 4. Expected Improvement\n",
    "# ---------------------------------------------------\n",
    "def expected_improvement(x, gp, y_best, xi):\n",
    "    x = np.atleast_2d(x)\n",
    "    mu, sigma = gp.predict(x, return_std=True)\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    improvement = mu - y_best - xi\n",
    "    Z = improvement / sigma\n",
    "    ei = improvement * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "    return ei\n",
    "\n",
    "def neg_ei(x, gp, y_best, xi):\n",
    "    return -expected_improvement(x.reshape(1, -1), gp, y_best, xi)[0]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Acquisition optimizer\n",
    "# ---------------------------------------------------\n",
    "def propose_location(gp, y_best, bounds, xi, n_restarts=30):\n",
    "    best_x = None\n",
    "    best_val = np.inf\n",
    "\n",
    "    for _ in range(n_restarts):\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        res = minimize(\n",
    "            fun=neg_ei,\n",
    "            x0=x0,\n",
    "            args=(gp, y_best, xi),\n",
    "            bounds=bounds,\n",
    "            method=\"L-BFGS-B\",\n",
    "            options={\"maxiter\": 200}\n",
    "        )\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return np.clip(best_x, bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 6. EXPLOIT candidate (local, low xi)\n",
    "# ---------------------------------------------------\n",
    "local_radius = 0.08\n",
    "eps = 1e-3\n",
    "\n",
    "exploit_bounds = []\n",
    "for i in range(dim):\n",
    "    if x_best[i] <= 0.02 or x_best[i] >= 0.98:\n",
    "        low = max(eps, x_best[i] - 0.02)\n",
    "        high = min(1 - eps, x_best[i] + 0.02)\n",
    "    else:\n",
    "        low = max(eps, x_best[i] - local_radius)\n",
    "        high = min(1 - eps, x_best[i] + local_radius)\n",
    "    exploit_bounds.append((low, high))\n",
    "\n",
    "exploit_bounds = np.array(exploit_bounds)\n",
    "\n",
    "x_exploit = propose_location(\n",
    "    gp,\n",
    "    y_best,\n",
    "    exploit_bounds,\n",
    "    xi=0.001,\n",
    "    n_restarts=30\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 7. EXPLORE candidate (global, higher xi)\n",
    "# ---------------------------------------------------\n",
    "global_bounds = np.array([(0.001, 0.999)] * dim)\n",
    "\n",
    "x_explore = propose_location(\n",
    "    gp,\n",
    "    y_best,\n",
    "    global_bounds,\n",
    "    xi=0.2,\n",
    "    n_restarts=40\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 8. Results\n",
    "# ---------------------------------------------------\n",
    "print(\"Current best y:\", y_best)\n",
    "print(\"Current best x:\", x_best)\n",
    "print(\"\\nNext EXPLOIT candidate:\", x_exploit)\n",
    "print(\"Next EXPLORE candidate:\", x_explore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_next_6dp = np.round(x_explore, 6)\n",
    "print(\"Rounded to:\", x_next_6dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "# Going with EXPLORE \n",
    "- repeatedly exploited the same basin (dims ~4, 5, 8 around mid–high values), and exploitation has already delivered strong but plateauing gains (~9.95).\n",
    "- The recent exploit point (≈9.91) did not improve the best, suggesting diminishing returns in that local region.\n",
    "- You’ve previously observed secondary high-performing regions (e.g. the 9.90–9.91 points far from the main basin), which means the landscape is likely multi-modal.\n",
    "- The EXPLORE candidate deliberately pushes into a high-uncertainty region (notably dim 2 ≈ 0.74 and different structure across dims 4–8), where the GP’s uncertainty is still high and upside remains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "# strategy summary\n",
    "- Earlier rounds: Exploit to lock in a strong local optimum.\n",
    "- Now: Explore to test whether another peak exists or to rule it out.\n",
    "- If the explore point underperforms → you can confidently return to exploitation.\n",
    "- If it performs well → you’ve discovered a new basin worth refining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
